{"cells":[{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":22587,"status":"ok","timestamp":1678781228254,"user":{"displayName":"鈴木慎平","userId":"00141692729728736613"},"user_tz":-540},"id":"5DLLQyZJy0eW","outputId":"a82b1e2b-4ada-454d-9cd2-21c9fe29e6a8"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1678781239206,"user":{"displayName":"鈴木慎平","userId":"00141692729728736613"},"user_tz":-540},"id":"TVS4hHrizRIq","outputId":"6d716396-4e84-49aa-88c3-22dec97be3c8"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Colab Notebooks/nlp_practice\n"]}],"source":["%cd /content/drive/MyDrive/Colab Notebooks/nlp_practice"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":427,"status":"ok","timestamp":1678768389720,"user":{"displayName":"鈴木慎平","userId":"00141692729728736613"},"user_tz":-540},"id":"i-4gNfOhls1J","outputId":"e4a8ec6a-44f3-42ba-a596-d562a72b7b85"},"outputs":[{"output_type":"stream","name":"stdout","text":["<_io.TextIOWrapper name='example.txt' mode='r' encoding='utf-8'>\n","こんにちは\n","こんばんは\n","さようなら\n","\n","こんにちは\n","こんばんは\n","さようなら\n","\n","こんにちは\n","こんばんは\n","さようなら\n","\n","Hello!\n"]}],"source":["#3-3-1 ファイル\n","\n","f = open('example.txt', 'r', encoding = 'utf-8')\n","print(f)\n","print(f.read())\n","print('\\n', end = '')\n","f.close()\n","\n","f = open('example.txt', 'r', encoding = 'utf-8')\n","print(f.readline(), end = '')\n","print(f.readline(), end = '')\n","print(f.readline())\n","print('\\n', end = '')\n","f.close()\n","\n","f = open('example.txt', 'r', encoding = 'utf-8')\n","for line in f:\n","  print(line, end = '')\n","print('\\n')\n","f.close()\n","\n","with open('example.txt', 'w', encoding = 'utf-8') as f:\n","  f.write('Hello!')\n","\n","with open('example.txt', 'r', encoding = 'utf-8') as f:\n","  print(f.read())\n","\n","with open('example.txt', 'w', encoding = 'utf-8') as f:\n","  f.write('こんにちは\\nこんばんは\\nさようなら')"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":853},"executionInfo":{"elapsed":3260,"status":"error","timestamp":1678768397137,"user":{"displayName":"鈴木慎平","userId":"00141692729728736613"},"user_tz":-540},"id":"Kf61P4MkmUgG","outputId":"9d441462-8923-48e5-a667-9230f6c664ef"},"outputs":[{"output_type":"stream","name":"stdout","text":["0    B\n","1    C\n","2    A\n","Name: grade, dtype: object\n","   高橋  B\n","0  佐藤  C\n","1  田中  A\n","    0  1\n","0  高橋  B\n","1  佐藤  C\n","2  田中  A\n","  name grade\n","0   高橋     B\n","1   佐藤     C\n","2   田中     A\n","  name grade\n","0   高橋     B\n","1   佐藤     C\n","2   田中     A\n","  name grade\n","0   高橋     B\n","1   佐藤     C\n","2   田中     A\n","  name grade\n","0   高橋     B\n","1   佐藤     C\n","2   田中     A\n"]},{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-4-57434bc1cc9c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0mdf8\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'1.jsonl'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    205\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 207\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/io/json/_json.py\u001b[0m in \u001b[0;36mread_json\u001b[0;34m(path_or_buf, orient, typ, dtype, convert_axes, convert_dates, keep_default_dates, numpy, precise_float, date_unit, encoding, encoding_errors, lines, chunksize, compression, nrows, storage_options)\u001b[0m\n\u001b[1;32m    610\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    611\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mjson_reader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 612\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mjson_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    613\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/io/json/_json.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    742\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensure_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    743\u001b[0m                 \u001b[0mdata_lines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 744\u001b[0;31m                 \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_object_parser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_combine_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_lines\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    745\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m             \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_object_parser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/io/json/_json.py\u001b[0m in \u001b[0;36m_get_object_parser\u001b[0;34m(self, json)\u001b[0m\n\u001b[1;32m    766\u001b[0m         \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtyp\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"frame\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 768\u001b[0;31m             \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFrameParser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    769\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    770\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtyp\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"series\"\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/io/json/_json.py\u001b[0m in \u001b[0;36mparse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    878\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parse_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parse_no_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/io/json/_json.py\u001b[0m in \u001b[0;36m_parse_no_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1131\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0morient\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"columns\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m             self.obj = DataFrame(\n\u001b[0;32m-> 1133\u001b[0;31m                 \u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprecise_float\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprecise_float\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1134\u001b[0m             )\n\u001b[1;32m   1135\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0morient\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"split\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Unexpected character found when decoding array value (2)"]}],"source":["#3-3-2,3 csv、tsv、json\n","\n","import pandas as pd\n","\n","df1 = pd.read_csv('example.csv', encoding = 'utf-8')\n","print(df1['grade'])\n","\n","df2 = pd.read_csv('example1.csv', encoding = 'utf-8')\n","print(df2)\n","\n","df3 = pd.read_csv('example1.csv', header = None, encoding = 'utf-8')\n","print(df3)\n","\n","df4 = pd.read_csv('example1.csv',  header = None, names = ('name', 'grade') ,encoding = 'utf-8')\n","print(df4)\n","\n","df5 = pd.read_csv('example.tsv', encoding = 'utf-8', sep = '\\t')\n","print(df5)\n","\n","df6 = pd.read_table('example.tsv', encoding = 'utf-8')\n","print(df6)\n","\n","df7 = pd.read_json('example.json', encoding = 'utf-8')\n","print(df7)\n","\n","df8 = pd.read_json('1.jsonl', lines = True, encoding = 'utf-8')\n","print(df8)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6avtK9-7xPVB"},"outputs":[],"source":["#3-4\n","#ぐるなび\n"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":703,"status":"ok","timestamp":1678768421957,"user":{"displayName":"鈴木慎平","userId":"00141692729728736613"},"user_tz":-540},"id":"FW5Q-QJ-y0Wc","outputId":"2c251daa-41ea-4f84-80fe-24a7b213c3a5"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","\n","\n","\t\tこれはExampleです。\n","\t\n","\n","これはExampleです。\n","He\n","llo\n","He\\nllo\n","今度からMkDocsでドキュメントを書こう。 \n","機械学習やるなら  がいいよね。 \n","機械学習やるならPythonがいいよね。\n","機械学習やるならPythonがいいよね。\n"]}],"source":["#4-2-1 テキストのクリーニング\n","#beautifulsoup4\n","#正規表現\n","\n","#beautifulsoup4\n","\n","html = \"\"\"\n","<html>\n","\t<body>\n","\t\tこれは<a href = \"http://example.com\">Example</a>です。\n","\t</body>\n","</html>\"\"\"\n","\n","from bs4 import BeautifulSoup\n","\n","def clean_html(html, strip = False):\n","  soup = BeautifulSoup(html, 'html.parser')\n","  text = soup.get_text(strip = strip)\n","  return text\n","\n","print(clean_html(html))\n","print(clean_html(html, strip = True))\n","\n","\n","#正規表現\n","\n","import re\n","\n","text = '今度からMkDocsでドキュメントを書こう。 #Python'\n","\n","def clean_hashtag(text):\n","  clearned_text = re.sub(r'#[a-zA-Z]+', '', text)\n","  return clearned_text\n","\n","print('He\\nllo')\n","print(r'He\\nllo')\n","print(clean_hashtag(text))\n","\n","text2 = '機械学習やるなら #Python がいいよね。 #jupyter'\n","\n","print(clean_hashtag(text2))\n","\n","def clean_hashtag2(text):\n","  cleaned_text = re.sub(r' #[a-zA-Z]+$', '', text)\n","  cleaned_text = re.sub(r' #([a-zA-Z]+) ', r'\\1', cleaned_text)\n","  return cleaned_text\n","\n","print(clean_hashtag2(text2))\n","\n","text3 = '機械学習やるなら #Python がいいよね。 #jupyter #pycon #scipy'\n","\n","def clean_hashtag3(text):\n","  cleaned_text = re.sub(r'( #[a-zA-Z]+)+$', '', text)\n","  cleaned_text = re.sub(r' #([a-zA-Z]+) ', r'\\1', cleaned_text)\n","  return cleaned_text\n","\n","print(clean_hashtag3(text3))"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":47071,"status":"ok","timestamp":1678768475313,"user":{"displayName":"鈴木慎平","userId":"00141692729728736613"},"user_tz":-540},"id":"LDKqK7DmTmXW","outputId":"4c603fa9-f1f6-406b-bea0-1485f07834c3"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting janome\n","  Downloading Janome-0.4.2-py2.py3-none-any.whl (19.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.7/19.7 MB\u001b[0m \u001b[31m50.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: janome\n","Successfully installed janome-0.4.2\n","彼女\t名詞,代名詞,一般,*,*,*,彼女,カノジョ,カノジョ\n","と\t助詞,格助詞,一般,*,*,*,と,ト,ト\n","国立\t名詞,一般,*,*,*,*,国立,コクリツ,コクリツ\n","新\t接頭詞,名詞接続,*,*,*,*,新,シン,シン\n","美術館\t名詞,一般,*,*,*,*,美術館,ビジュツカン,ビジュツカン\n","へ\t助詞,格助詞,一般,*,*,*,へ,ヘ,エ\n","行っ\t動詞,自立,*,*,五段・カ行促音便,連用タ接続,行く,イッ,イッ\n","た\t助動詞,*,*,*,特殊・タ,基本形,た,タ,タ\n","。\t記号,句点,*,*,*,*,。,。,。\n","\n","彼女\n","と\n","国立\n","新\n","美術館\n","へ\n","行っ\n","た\n","。\n","\n","彼女\t名詞,代名詞,一般,*,*,*,彼女,カノジョ,カノジョ\n","国立\t名詞,一般,*,*,*,*,国立,コクリツ,コクリツ\n","美術館\t名詞,一般,*,*,*,*,美術館,ビジュツカン,ビジュツカン\n","\n","彼女\t名詞,代名詞,一般,*,*,*,彼女,カノジョ,カノジョ\n","と\t助詞,並立助詞,*,*,*,*,と,ト,ト\n","国立新美術館\t名詞,固有名詞,一般,*,*,*,国立新美術館,コクリツシンビジュツカン,コクリツシンビジュツカン\n","へ\t助詞,格助詞,一般,*,*,*,へ,ヘ,エ\n","行っ\t動詞,自立,*,*,五段・カ行促音便,連用タ接続,行く,イッ,イッ\n","た\t助動詞,*,*,*,特殊・タ,基本形,た,タ,タ\n","。\t記号,句点,*,*,*,*,。,。,。\n"]}],"source":["#4-2-2 単語分割\n","\n","!pip install janome\n","\n","from janome.tokenizer import Tokenizer\n","\n","text = '彼女と国立新美術館へ行った。'\n","t = Tokenizer()\n","for token in t.tokenize(text):\n","  print(token)\n","\n","print()\n","\n","tt = Tokenizer(wakati = True)\n","for token in tt.tokenize(text):\n","  print(token)\n","\n","print()\n","\n","from janome.analyzer import Analyzer\n","from janome.tokenfilter import POSKeepFilter\n","\n","token_filters = [POSKeepFilter('名詞')]\n","a = Analyzer(token_filters = token_filters)\n","for token in a.analyze(text):\n","  print(token)\n","\n","print()\n","\n","ttt = Tokenizer(udic = 'userdic.csv' , udic_enc = 'utf-8')\n","for token in ttt.tokenize(text):\n","  print(token)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":797,"status":"ok","timestamp":1678107881652,"user":{"displayName":"鈴木慎平","userId":"00141692729728736613"},"user_tz":-540},"id":"s0tkpyW19Qud","outputId":"c37bf7a4-e5c2-4164-cbd9-ca79bc90dbec"},"outputs":[{"name":"stdout","output_type":"stream","text":["0万0・0ドル\n","0万0000・00ドル\n","{'係', '怒', 'ところ', '秋', 'はじめ', '家', '略', '例', '市', '簿', '国', 'こと', '木', 'わたし', 'とき', 'レ', '度', '段', 'あと', 'これら', 'もと', '文', '類', '近く', 'がら', '面', '九', '五', 'うち', '点', '用', 'など', '村', '前', 'そこ', '自分', 'そう', '台', 'あたり', '首', '以降', '分', '秒', '書', '六', '我々', '時間', '下記', '本当', '未満', 'くせ', '箇月', '高', 'さん', '品', '元', '全部', '何', 'ほか', '間', 'こっち', 'みんな', 'どちら', '系', '新た', '見', 'そちら', 'どれ', 'ひと', '各', '都', 'から', '様々', 'みなさん', 'あっち', '箇所', 'こちら', 'それ', '感', '字', 'かく', '府', 'たび', 'わけ', '所', '年', '紀', '以下', 'あちら', '関係', 'いろいろ', '四', 'ごと', '士', '時点', '先', 'ヶ所', '自体', '何人', '際', 'あなた', '名', '冬', 'なに', '時', '道', 'すね', 'もの', '感じ', 'まさ', '内', '力', 'ぶり', 'なん', '方', 'どこか', 'どっち', '彼', 'がい', '週', '別', '会', '観', '女', '毎', '中', 'よそ', '以上', '情', 'まま', '千', '場', '外', 'まとも', '連', '線', '哀', 'たち', '年生', '第', '事', 'あそこ', 'そで', '左', 'まし', 'ぜんぶ', '集', '七', '誌', '課', '一', 'みつ', '月', 'ここ', 'すか', '歴', '通', '私', 'なかば', '火', '区', '万', '境', '半ば', '夏', '以後', 'いま', 'どこ', 'しよう', '今回', '人', '列', '右', '違い', '今', '室', '奴', '誰', '土', 'てん', '二', '一つ', '匹', 'さまざま', 'しかた', '扱い', '町', '円', '三', 'さらい', '日', '名前', '億', '法', '回', '百', '前回', 'ふく', 'だめ', 'あな', 'それなり', '的', '個', '幾つ', 'ひとつ', '束', '向こう', 'ハイ', 'かやの', '上記', 'いつ', '式', 'その後', '作', 'どっか', '俺', '部', 'きた', '子', '気', '輪', '員', '下', '歳', '目', '頃', '界', '春', '八', '彼女', 'とおり', '等', 'へん', 'ごろ', '多く', 'ぺん', '十', 'はるか', '形', '地', '者', '上', 'なか', '席', 'やつ', '伸', '体', '達', '男', '喜', '口', 'いや', 'ため', '性', '確か', '化', 'べつ', 'あれ', 'かたち', '以前', 'おまえ', '後', '兆', 'ヵ月', 'ちゃん', 'おおまか', '水', '話', 'ちゃ', 'ヵ所', '楽', 'これ', '様', '他', '婦', 'たくさん', 'もん', 'はず', '場合', 'おれ', '毎日', '論', '方法', '金', 'ずつ', 'いくつ', 'それぞれ', 'よう', 'みたい', '結局', 'カ月', 'ほう', '数', '行', 'すべて', 'そっち', '器', 'ヶ月', '手段', 'ごっちゃ', '校', '屋', '店', '枚', 'カ所', '県', '手', '同じ', '玉', '次'}\n","<generator object Tokenizer.__tokenize_stream at 0x7f0fccb00f90>\n","['リンゴ', 'を', 'か', '買う']\n"]}],"source":["#4-2-3 単語の正規化\n","\n","import re\n","\n","def normalize_number(text):\n","  replaced_text = re.sub(r'\\d+', '0', text)\n","  return replaced_text\n","\n","text = '2万0689・24ドル'\n","print(normalize_number(text))\n","\n","def normalize_number2(text):\n","  replaced_text = re.sub(r'\\d', '0', text)\n","  return replaced_text\n","\n","print(normalize_number2(text))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16207,"status":"ok","timestamp":1678155822319,"user":{"displayName":"鈴木慎平","userId":"00141692729728736613"},"user_tz":-540},"id":"dF89LykUFJUa","outputId":"f24cdb1d-ef88-4331-f176-627ddbd028be"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: janome in /usr/local/lib/python3.8/dist-packages (0.4.2)\n","{'確か', '全部', 'いろいろ', '形', 'すべて', 'あれ', 'いつ', '男', '万', '情', '口', 'ぺん', '楽', '類', 'すね', '時点', '列', 'がら', '半ば', '自分', 'ため', '下記', '観', '同じ', '等', '内', '名', '後', '簿', '化', 'まとも', '事', 'こっち', '例', '気', '束', '未満', 'よう', 'くせ', '場', 'ところ', '俺', '扱い', 'かやの', '様', '以上', '外', 'わたし', '通', 'かく', 'たび', '士', '秒', '所', '自体', '歳', 'ひと', '子', '五', '左', '集', 'こちら', 'まま', '時', 'ヶ月', 'がい', '地', '枚', '行', '伸', 'みなさん', '市', '一つ', '本当', '達', 'そう', 'どっち', '様々', '店', '前', 'それなり', '紀', 'みたい', '中', 'あな', '課', 'どこ', '室', '哀', '以前', '間', '屋', 'たくさん', 'すか', '見', '村', '席', '用', 'みつ', 'そで', 'とおり', '者', '関係', 'まし', '怒', 'ごろ', '法', '方法', '県', 'おれ', '輪', 'こと', '時間', 'ヶ所', '近く', 'とき', '道', '誰', '分', '兆', 'はず', '多く', '次', 'など', '感じ', 'きた', '右', '係', '六', '国', '年生', '上', '的', 'あっち', '会', 'あそこ', '八', '箇月', '以下', '誌', '系', 'もん', '今回', '町', 'ちゃ', '頃', '彼女', 'ちゃん', '週', '別', '十', '何人', '土', 'なかば', '秋', 'そっち', 'うち', '我々', 'レ', 'てん', '九', '上記', '今', '連', 'なに', '喜', '点', '略', '金', 'これら', 'だめ', '府', 'ひとつ', '品', '都', 'その後', '部', '境', 'いま', '段', '七', '夏', '歴', '以降', '界', '体', 'はじめ', 'なか', 'それ', '水', '向こう', 'やつ', 'ヵ月', 'はるか', '目', 'カ所', '器', '場合', 'ずつ', 'あちら', 'さまざま', 'ハイ', '円', 'ここ', 'そちら', 'もと', '前回', '四', '各', 'しよう', '台', '春', '第', '木', '月', '千', 'べつ', '私', 'あたり', 'から', 'ほう', '式', '冬', 'いや', '結局', '三', 'ふく', '匹', '家', '百', 'どっか', 'ごと', '論', 'しかた', '何', '員', 'それぞれ', '下', 'たち', 'ごっちゃ', '面', '元', '方', '毎日', '性', '幾つ', 'ほか', 'あと', '度', 'おまえ', '回', '彼', '個', 'いくつ', 'さん', '線', '他', 'ぶり', '二', '火', '年', 'そこ', '手段', '文', '話', 'まさ', '奴', 'どれ', '億', '力', '毎', '手', '書', 'へん', '玉', '一', '首', 'なん', 'わけ', '字', 'よそ', 'カ月', '高', '数', 'どちら', '校', 'おおまか', '感', 'もの', '人', '婦', '箇所', 'さらい', '先', 'みんな', '新た', '日', '女', 'あなた', 'どこか', '作', '区', 'これ', 'かたち', '際', '以後', '名前', 'ヵ所', '違い', 'ぜんぶ'}\n","['リンゴ', 'を', 'か', '買う']\n","[1151, 6, 7901]\n","[[0 0 1 2]\n"," [0 3 4 5]\n"," [6 7 8 9]]\n","[[1 2 0 0]\n"," [3 4 5 0]\n"," [6 7 8 9]]\n","[[0 1 2]\n"," [3 4 5]\n"," [7 8 9]]\n","[[0 1 2]\n"," [3 4 5]\n"," [6 7 8]]\n","[[10 10  1  2]\n"," [10  3  4  5]\n"," [ 6  7  8  9]]\n"]}],"source":["#4-2-4, 5, 6\n","#4-2-4 ストップワードの除去\n","\n","#!pip install requests\n","import requests\n","!pip install janome\n","from janome.tokenizer import Tokenizer\n","\n","url = \"http://svn.sourceforge.jp/svnroot/slothlib/CSharp/Version1/SlothLib/NLP/Filter/StopWord/word/Japanese.txt\"\n","r = requests.get(url)\n","tmp = r.text.split('\\r\\n')\n","with open('Japanese.txt', 'w', encoding = 'utf-8') as f:\n","  for i in range(len(tmp)):\n","    if len(tmp[i]) < 1:\n","        continue\n","    f.write(tmp[i] + '\\n')\n","\n","with open('Japanese.txt', 'r', encoding = 'utf-8') as f:\n","  stopwords = [w.strip() for w in f]\n","  stopwords = set(stopwords)\n","  print(stopwords)\n","\n","def remove_stopwords(words, stopwords):\n","  words = [w for w in words if w not in stopwords]\n","  return words\n","\n","t = Tokenizer(wakati = True)\n","text = 'リンゴをいくつか買う'\n","words = t.tokenize(text)\n","print(remove_stopwords(words, stopwords))\n","\n","\n","with open('ja.text8', 'r', encoding = 'utf-8') as f:\n","  text = f.read()\n","  words = text.split()\n","\n","#!pip install collections\n","from collections import Counter\n","Counter(['cat', 'dog', 'cat'])\n","\n","fdist = Counter(words)\n","fdist.most_common(n=10)\n","\n","\n","#4-2-5 単語のID化\n","\n","UNK = '<UNK>'\n","PAD = '<PAD>'\n","vocab = {PAD: 0, UNK: 1}\n","for word, _ in fdist.most_common():\n","  vocab[word] = len(vocab)\n","\n","words = ['私', 'は', '元気']\n","word_ids = [vocab.get(w, vocab[UNK]) for w in words]\n","print(word_ids)\n","\n","\n","#4-2-6 パディング\n","\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","sequences = [[1, 2], [3, 4, 5], [6, 7, 8, 9]]\n","print(pad_sequences(sequences))\n","print(pad_sequences(sequences, padding = 'post'))\n","print(pad_sequences(sequences, maxlen = 3))\n","print(pad_sequences(sequences, maxlen = 3, truncating = 'post'))\n","print(pad_sequences(sequences, value = 10))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MrVeUg2bIjRM","outputId":"ce96b6df-3e92-43d4-de86-8953d5524363"},"outputs":[{"name":"stdout","output_type":"stream","text":["Tokenization only.\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.8/dist-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["0.4010\n","Clean html.\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.8/dist-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\n","/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  warnings.warn(\n","/usr/local/lib/python3.8/dist-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["0.4060\n","Normalize number.\n","0.3970\n","Base form\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.8/dist-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["0.3940\n","Lower text.\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.8/dist-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\n"]}],"source":["#4-3-2, 3, 4 前処理の実践\n","\n","#4-3-2,3 データセットの準備\n","\n","#utils.py\n","import string\n","import pandas as pd\n","import requests\n","\n","from sklearn.feature_extraction.text import CountVectorizer\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import accuracy_score\n","\n","#テキストの英語の割合がthresholdよりも多ければ英語とみなす\n","def filter_by_ascii_rate(text, threshold = 0.9):\n","  ascii_letters = set(string.printable)\n","  rate = sum(c in ascii_letters for c in text) / len(text)\n","  return rate <= threshold\n","\n","def load_dataset(filename, n = 5000, state = 6):                                                    \n","  df = pd.read_csv(filename, sep = '\\t')\n","\n","  #extract Japanese.txt\n","  is_jp = df.review_body.apply(filter_by_ascii_rate)\n","  df = df[is_jp]\n","\n","  df = df.sample(frac = 1, random_state = state) #shuffle\n","  grouped = df.groupby('star_rating')\n","  df = grouped.head(n=n)\n","  return df.review_body.values, df.star_rating.values\n","\n","def train_and_eval(x_train, y_train, x_test, y_test, lowercase = False, tokenize = None, preprocessor = None):\n","  vectorizer = CountVectorizer(lowercase = lowercase, tokenizer = tokenize, preprocessor = preprocessor)\n","  x_train_vec = vectorizer.fit_transform(x_train)\n","  x_test_vec = vectorizer.transform(x_test)\n","  clf = LogisticRegression(solver='liblinear')\n","  clf.fit(x_train_vec, y_train)\n","  y_pred = clf.predict(x_test_vec)\n","  score = accuracy_score(y_test, y_pred)\n","  print('{:.4f}'.format(score))\n","\n","\n","#preprocessing.py\n","import re\n","\n","from bs4 import BeautifulSoup\n","from janome.tokenizer import Tokenizer\n","t = Tokenizer()\n","\n","def clean_html(html, strip = False):\n","  soup = BeautifulSoup(html, 'html.parser')\n","  text = soup.get_text(strip = strip)\n","  return text\n","\n","def tokenize(text):\n","  return t.tokenize(text, wakati = True)\n","\n","def tokenize_base_form(text):\n","  tokens = [token.base_form for token in t.tokenize(text)]\n","  return tokens\n","\n","def normalize_number(text, reduce = False):\n","  if reduce:\n","    normalize_text = re.sub(r'\\d+', '0', text)\n","  else:\n","    normalize_text = re.sub(r'\\d', '0', text)\n","  return normalize_text \n","\n","\n","#4-3-4 モデルの学習と評価\n","\n","#train.py\n","from sklearn.model_selection import train_test_split\n","\n","#from preprocessing import *\n","#from utils import *\n","\n","def main():\n","  x, y = load_dataset('amazon_reviews_multilingual_JP_v1_00.tsv', n = 1000)\n","  x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 42)\n","  print('Tokenization only.')\n","  train_and_eval(x_train, y_train, x_test, y_test, tokenize = tokenize)\n","  print('Clean html.')\n","  train_and_eval(x_train, y_train, x_test, y_test, tokenize = tokenize, preprocessor = clean_html)\n","  print('Normalize number.')\n","  train_and_eval(x_train, y_train, x_test, y_test, tokenize = tokenize, preprocessor = normalize_number)\n","  print('Base form')\n","  train_and_eval(x_train, y_train, x_test, y_test, tokenize = tokenize_base_form)\n","  print('Lower text.')\n","  train_and_eval(x_train, y_train, x_test, y_test, tokenize = tokenize, lowercase = True)\n","\n","#if __main__ == '__main__':\n","  #main()\n","\n","main()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":388},"executionInfo":{"elapsed":302,"status":"ok","timestamp":1678189177665,"user":{"displayName":"鈴木慎平","userId":"00141692729728736613"},"user_tz":-540},"id":"TZSJkAwODDD6","outputId":"ac2714cb-9470-4b73-e95c-fb4b4f9215d2"},"outputs":[{"name":"stdout","output_type":"stream","text":["       drink size\n","0       Cola    S\n","1       Cola    M\n","2  Green Tea    L\n","3       Milk    M\n","['S' 'M' 'L']\n","       drink  size\n","0       Cola     0\n","1       Cola     1\n","2  Green Tea     2\n","3       Milk     1\n","[0 1 2]\n"]},{"data":{"text/html":["\n","  <div id=\"df-7f9cbcfa-ca2b-41c6-b61c-e34ad84c2a6d\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>size</th>\n","      <th>drinklabel</th>\n","      <th>drink_Cola</th>\n","      <th>drink_Green Tea</th>\n","      <th>drink_Milk</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7f9cbcfa-ca2b-41c6-b61c-e34ad84c2a6d')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-7f9cbcfa-ca2b-41c6-b61c-e34ad84c2a6d button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-7f9cbcfa-ca2b-41c6-b61c-e34ad84c2a6d');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["   size  drinklabel  drink_Cola  drink_Green Tea  drink_Milk\n","0     0           0           1                0           0\n","1     1           0           1                0           0\n","2     2           1           0                1           0\n","3     1           2           0                0           1"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["#5-2-1\n","\n","#質的変数\n","#商品名は名義特徴量\n","#サイズは順序特徴量\n","import pandas as pd\n","\n","df = pd.DataFrame([\n","  ['Cola', 'S'],\n","  ['Cola', 'M'],\n","  ['Green Tea', 'L'],\n","  ['Milk', 'M']\n","], columns = ['drink', 'size'])\n","print(df.head())\n","\n","#値の種類をunique()で確認\n","print(df['size'].unique())\n","\n","#順序特徴量のマッピング\n","#サイズの列を辞書で値をmap()で変換させる\n","size2int = {'S': 0, 'M': 1, 'L': 2}\n","df['size'] = df['size'].map(size2int)\n","print(df.head())\n","\n","print(df['size'].unique())\n","\n","#名義特徴量の変換\n","from sklearn.preprocessing import LabelEncoder\n","encoder = LabelEncoder()\n","df['drinklabel'] = encoder.fit_transform(df['drink'])\n","df.head()\n","\n","#名義特徴量はone-hotエンコーディングする\n","print(pd.get_dummies(df))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":441},"executionInfo":{"elapsed":310,"status":"ok","timestamp":1678190668095,"user":{"displayName":"鈴木慎平","userId":"00141692729728736613"},"user_tz":-540},"id":"u_6wHEeE1rBM","outputId":"36680454-3a9e-459e-cbc5-5cd0c6fbfa85"},"outputs":[{"name":"stdout","output_type":"stream","text":["0     7.25000\n","1    71.28330\n","2     3.98200\n","3    43.90123\n","Name: Fare, dtype: float64\n","0    False\n","1     True\n","2    False\n","3     True\n","Name: Fare, dtype: bool\n","0    0\n","1    1\n","2    0\n","3    1\n","Name: Fare, dtype: int64\n"]},{"data":{"text/html":["\n","  <div id=\"df-718d5ee0-2433-45b9-beee-d114ba7840c2\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Fare</th>\n","      <th>FareInt</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>7.25000</td>\n","      <td>7</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>71.28330</td>\n","      <td>71</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3.98200</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>43.90123</td>\n","      <td>44</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-718d5ee0-2433-45b9-beee-d114ba7840c2')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-718d5ee0-2433-45b9-beee-d114ba7840c2 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-718d5ee0-2433-45b9-beee-d114ba7840c2');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["       Fare  FareInt\n","0   7.25000        7\n","1  71.28330       71\n","2   3.98200        4\n","3  43.90123       44"]},"execution_count":22,"metadata":{},"output_type":"execute_result"}],"source":["#5-2-2　量的変数の処理\n","\n","import pandas as pd\n","\n","df = pd.DataFrame([\n","    [7.2500],\n","    [71.2833],\n","    [3.9820],\n","    [43.90123]\n","], columns = ['Fare'])\n","print(df['Fare'])\n","#閾値を決めて2値化\n","print(df['Fare'] > 10)\n","#真理値をastypeで整数値へ\n","print((df['Fare'] > 10).astype(int))\n","\n","#丸め（値の精度は高すぎる必要はない）\n","df['FareInt'] = df['Fare'].round().astype(int)\n","df[['Fare', 'FareInt']].head()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":403},"executionInfo":{"elapsed":381,"status":"error","timestamp":1678199876753,"user":{"displayName":"鈴木慎平","userId":"00141692729728736613"},"user_tz":-540},"id":"L8H_SMIk6Jm6","outputId":"014b5397-6061-40d5-e3f0-f0b304ffbd2e"},"outputs":[{"name":"stdout","output_type":"stream","text":["[[0 1 1 0 1 1 1 1]\n"," [1 0 0 1 0 0 0 0]]\n","{'the': 7, 'cat': 2, 'is': 4, 'out': 6, 'of': 5, 'bag': 1, 'dogs': 3, 'are': 0}\n","[[0 1 1 0 1 1 1 2]\n"," [1 0 0 1 0 0 0 0]]\n","[[0.         0.37729199 0.37729199 0.         0.37729199 0.37729199\n","  0.37729199 0.53689271]\n"," [0.6316672  0.         0.         0.6316672  0.         0.\n","  0.         0.44943642]]\n"]},{"ename":"AttributeError","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-58-fceb96bd692b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0mtfidf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtfidf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0mvocab\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_feature_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#colabだとなぜかエラー\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtfidf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvocab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'TfidfVectorizer' object has no attribute 'get_feature_names'"]}],"source":["#5-3-1　テキストのベクトル表現　ngram BoW\n","\n","#one-hotエンコーディング\n","from sklearn.feature_extraction.text import CountVectorizer\n","vectorizer = CountVectorizer(binary = True)\n","docs = ['the cat is out of the bag', 'dogs are']\n","bow = vectorizer.fit_transform(docs)\n","print(bow.toarray())\n","print(vectorizer.vocabulary_)\n","#print(vectorizer.get_feature_names())\n","\n","#countエンコーディング\n","vectorizer = CountVectorizer(binary = False)\n","docs = ['the cat is out of the bag', 'dogs are']\n","bow = vectorizer.fit_transform(docs)\n","print(bow.toarray())\n","\n","#tf-idf\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","vectorizer = TfidfVectorizer()\n","docs = ['the cat is out of the bag', 'the dogs are']\n","tfidf = vectorizer.fit_transform(docs)\n","print(tfidf.toarray())\n","vocab = vectorizer.get_feature_names() #colabだとなぜかエラー\n","pd.DataFrame(tfidf.toarray(), columns = vocab).round(2)\n","\n","#分書\n","from janome import Tokenizer\n","t = Tokenizer(wakati=True)\n","vectorizer = CountVectrizer(tokenizer = t.tokenize)\n","docs = ['猫の子子猫', '獅子の子子獅子']\n","bow = vectorizer.fit_transform(docs)\n","vocab = vectorizer.get_feature_names()\n","pd.DataFrame(bow.toarray(), columns = vocab)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":275,"status":"ok","timestamp":1678200629071,"user":{"displayName":"鈴木慎平","userId":"00141692729728736613"},"user_tz":-540},"id":"VUf2IlFMfLMA","outputId":"d20d3d68-8ebe-430e-e3c8-350981be5434"},"outputs":[{"name":"stdout","output_type":"stream","text":["{'the': 12, 'cat': 2, 'is': 6, 'out': 10, 'of': 8, 'bag': 1, 'the cat': 14, 'cat is': 3, 'is out': 7, 'out of': 11, 'of the': 9, 'the bag': 13, 'dogs': 4, 'are': 0, 'dogs are': 5}\n"]}],"source":["#おまけ 語順を気にする\n","\n","from sklearn.feature_extraction.text import CountVectorizer\n","vectorizer = CountVectorizer(ngram_range = (1, 2))\n","docs = ['the cat is out of the bag', 'dogs are']\n","bow = vectorizer.fit_transform(docs)\n","print(vectorizer.vocabulary_)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":468122,"status":"ok","timestamp":1678203222965,"user":{"displayName":"鈴木慎平","userId":"00141692729728736613"},"user_tz":-540},"id":"gN_K5pnnjMB-","outputId":"3128db6c-2256-462f-c875-338bab6f582b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: janome in /usr/local/lib/python3.8/dist-packages (0.4.2)\n","Tokenization\n","Binary\n","0.8385\n","Count\n","0.8360\n","TF-IDF\n","0.8520\n","Bigram\n","0.8545\n"]}],"source":["#5-4-2 ベクトル表現の実践 データセットの準備\n","\n","#utils.py\n","import string\n","import pandas as pd\n","\n","from sklearn.feature_extraction.text import CountVectorizer\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import accuracy_score\n","\n","#テキストの英語の割合がthresholdよりも多ければ英語とみなす\n","def filter_by_ascii_rate(text, threshold = 0.9):\n","  ascii_letters = set(string.printable)\n","  rate = sum(c in ascii_letters for c in text) / len(text)\n","  return rate <= threshold\n","\n","def load_dataset(filename, n = 5000, state = 6):                                                    \n","  df = pd.read_csv(filename, sep = '\\t')\n","\n","  #Converts multi-class to binary-class\n","\n","  mapping = {1: 0, 2: 0, 4: 1, 5: 1}\n","  df = df[df.star_rating != 3]\n","  df.star_rating = df.star_rating.map(mapping)\n","\n","  #extract Japanese.txt\n","  is_jp = df.review_body.apply(filter_by_ascii_rate)\n","  df = df[is_jp]\n","\n","  df = df.sample(frac = 1, random_state = state) #shuffle\n","  grouped = df.groupby('star_rating')\n","  df = grouped.head(n=n)\n","  return df.review_body.values, df.star_rating.values\n","\n","def train_and_eval(x_train, y_train, x_test, y_test, vectorizer):\n","  x_train_vec = vectorizer.fit_transform(x_train)\n","  x_test_vec = vectorizer.transform(x_test)\n","  clf = LogisticRegression(solver='liblinear')\n","  clf.fit(x_train_vec, y_train)\n","  y_pred = clf.predict(x_test_vec)\n","  score = accuracy_score(y_test, y_pred)\n","  print('{:.4f}'.format(score))\n","\n","\n","#preprocessing.py\n","import re\n","from bs4 import BeautifulSoup\n","!pip install janome\n","from janome.tokenizer import Tokenizer\n","t = Tokenizer()\n","\n","def clean_html(html, strip = False):\n","  soup = BeautifulSoup(html, 'html.parser')\n","  text = soup.get_text(strip = strip)\n","  return text\n","\n","def tokenize(text):\n","  return t.tokenize(text, wakati = True)\n","\n","#train.py\n","from sklearn.model_selection import train_test_split\n","from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n","\n","#from preprocessing import *\n","#from utils import *\n","\n","def main():\n","  x, y = load_dataset('amazon_reviews_multilingual_JP_v1_00.tsv', n = 5000)\n","  print('Tokenization')\n","  x = [clean_html(text, strip = True) for text in x]\n","  x = [' '.join(tokenize(text)) for text in x]     \n","  x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 42)\n","\n","  #出現するかどうかone-hot\n","  print('Binary')\n","  vectorizer = CountVectorizer(binary = True)\n","  train_and_eval(x_train, y_train, x_test, y_test, vectorizer)\n","\n","  #出現回数one-hot\n","  print('Count')\n","  vectorizer = CountVectorizer(binary = False) \n","  train_and_eval(x_train, y_train, x_test, y_test, vectorizer) \n","\n","  #TF-IDF\n","  print('TF-IDF')\n","  vectorizer = TfidfVectorizer()\n","  train_and_eval(x_train, y_train, x_test, y_test, vectorizer)\n","\n","  #順序をもつBigram\n","  print('Bigram')\n","  vectorizer = TfidfVectorizer(ngram_range = (1, 2))\n","  train_and_eval(x_train, y_train, x_test, y_test, vectorizer)\n","\n","#if __main__ == '__main__':\n","  #main()\n","\n","main()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1678240968581,"user":{"displayName":"鈴木慎平","userId":"00141692729728736613"},"user_tz":-540},"id":"jUlX2AuPoLaG","outputId":"6be18256-4fb2-4c8f-81c7-50f993979ca2"},"outputs":[{"name":"stdout","output_type":"stream","text":["[[0.   0.  ]\n"," [0.25 0.25]\n"," [0.5  0.5 ]\n"," [1.   1.  ]]\n","[[-1.         -1.34164079]\n"," [-1.         -0.4472136 ]\n"," [ 1.          0.4472136 ]\n"," [ 1.          1.34164079]]\n"]}],"source":["#5-5　特徴量のスケーリング\n","\n","#正規化\n","from sklearn.preprocessing import MinMaxScaler\n","\n","data = [[-1, 2], [-0.5, 6], [0, 10], [1, 18]]\n","scaler = MinMaxScaler()\n","scaler.fit(data)\n","print(scaler.transform(data))\n","\n","#標準化\n","from sklearn.preprocessing import StandardScaler\n","\n","data = [[0, 10], [0, 15], [1, 20], [1, 25]]\n","scaler = StandardScaler()\n","scaler.fit(data)\n","print(scaler.transform(data))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":624},"executionInfo":{"elapsed":97128,"status":"error","timestamp":1678244572086,"user":{"displayName":"鈴木慎平","userId":"00141692729728736613"},"user_tz":-540},"id":"EoliXfcy8A2a","outputId":"41e275d6-5875-4d21-cfae-66391c3b92b0"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: janome in /usr/local/lib/python3.8/dist-packages (0.4.2)\n","Loading...\n","['現在、地球温暖化の悪影響が、ここまで顕在化しているとは<br />想像していませんでした。特に、このまま海面温度が上昇を<br />続けると、早晩、南極・北極の氷が大規模に溶けることに<br />よって相当の範囲の陸地が海に没し、十億人単位での難民が<br />発生するという事実には、本当に衝撃を受けました。<br /><br />ある人が、「人間は地球にすくう癌細胞のようである。<br />増殖・破壊を続け、最終的には自らも寄生先の死によって<br />滅ぶ運命にある」と言っていたことを思い出しました。<br /><br />一方、主人公であるゴア氏が、聴衆が数十人〜数百人程度の<br />世界中の教室・会議場をまわって危機を訴えるという、地道<br />な「草の根」の活動にも大変感銘を受けました。個人的には、<br />ゴア氏には、ブッシュ氏との大統領戦における、「賢いが<br />傲慢で冷徹」というイメージが強かったのですが、およそ<br />そんなことはない（＝きっと、ブッシュ陣営のネガティブ・<br />キャンペーンの影響を愚かにも受けていたのでしょう）、<br />信念を持ち、実行力が伴った、特筆すべき政治家であること<br />も分かりました。<br /><br />温暖化の危機、ゴア氏ほかの活動家・学者の行動に対する<br />不明を恥じると共に、自らもCO2ゼロ化に向けて早速行動<br />したいと思いました。<br /><br />なお、当作品は、語られる事象のすべてが具体的かつ<br />客観的に科学的根拠に支えられており、ドキュメンタリー<br />としても秀逸だと思います。<br /><br />是非ご覧になってみて下さい。お奨めします。'\n"," 'このアクション映画ほど、男気を感じたものはあったのだろうか。<br />シンプル構成で時間をたっぷりと使った中身のあるアクション映画です。<br /><br />劇中、鉄斧を持った闇のサイコ集団（敵）が出てくるんですが<br />スタローンがこれでもかと、鉄拳制裁っ！するあたりはまさに圧巻の連続です。<br /><br />シンプルな映画ですが、家族で見ててハラハラドキドキします。<br /><br />また、この頃の映画って何か麻薬的な中毒性がありますよね。<br />何度も映画の世界に引きずり込まれてしまいます。<br /><br />最近のアクション映画に物足りなさを感じている方、ぜひこのスタローンアクションを見て<br />日々の疲れきった人生にスパイスを与えましょう。'\n"," 'このアプリを入れて以来、かなりお世話になりました。<br />私の場合、PCで作成したデータや画像を出先で「kindle fireHD」「androidタブレット（10.1インチ）」「スマホ」で閲覧、もしくはその逆・・・という使い方がメインでした。<br />作成は主にPC、簡単な情報を人に見せる場合はkindle fire HD、Excelデータなど細かい画面を多人数で閲覧する時はタブレット、自分で確認するだけの場合はスマホ。<br />TPOに合わせて最低限の荷物で済むのが、とても便利・・・でした。<br /><br />確かに、それなりの「技術」にはそれなりの「対価」を支払う必要があるのでしょう・・・<br />使用容量によって「無料」「有料」があるのは、データ保存するサーバーの関係上「当然」の事と思います。<br />しかし、いきなり<br />「この先、登録できる端末は2台まで！それ以上使いたければ月額費が必要です」<br /><br />Evernoteの知名度がうなぎ登りになり、関連書籍が多数発売され、関連商品が高額で販売され・・・<br />えぇ、嫌な予感はしていましたよ・・・無料版に何らかの制限（保存容量が更に減るとか）が付くかも？と。<br />まさか、無料版の登録台数を2台に制限とは・・・<br /><br />他のアプリを探すことにしました。<br />今まで有難う、Evernote。<br /><br />｛追記｝<br />残念ながら「dropbox」はkindle非対応なので、kindle・android・PC全てに対応している「box」を使う事に決めました。<br />Excelデータを閲覧する際、Evernoteよりも一手間掛かってしまうのですが・・・仕方ないです。<br /><br />｛追記２｝<br />先ほどEvernoteからメールが来ました。<br />プライバシーポリシー変更の変更・・・との事。<br />「不評だったのでEvernote社員がお客様のページを閲覧・監視する体制は辞めました」・・・っておいっ！！<br />確かにセキュリティの観点から「ある程度の監視」は管理者として必要なのかもしれないけど・・・<br />そこは「不評だったから辞める」って問題なのか？？<br />特にビジネスで使ってる人間にとって、クラウドの外部流出は「死活問題」だろ？<br />「ビジネスの場でEvernoteを便利に活用してください」的な紹介をさんざんしておいて・・・ておいっ！！ 確かにセキュリティの観点から「ある程度の監視」は管理者として必要なのかもしれないけど・・・ そこは「不評だったから辞める」って問題なのか？？ 特にビジネスで使ってる人間にとって、クラウドの外部流出は「死活問題」だろ？ 「ビジネスの場でEvernoteを便利に活用してください」的な紹介をさんざんしておいて・・・'\n"," ...\n"," 'この作品は、日本語吹き替えも素晴らしい（特にヒロインの女性）のに<br />字幕のみだったのが残念。<br />映像も音楽もＤＶＤとの違いが判らない出来栄え。'\n"," '守銭奴が集まったアマチュアメーカー 相変わらずのえげつない商法ですな 映像は革命的なのに メーカーの皆々様の脳内は江戸時代で止まってるのではないでしょうか この映画会社で製作されたのを不運と思うしかありませんね 別の某メーカーさんなら 特典満載の3Dでリリースされただろうと思うと また情けなくなりますね'\n"," 'わたくしの\\u3000アイポットタッチとは、相性が悪いのか？ちょいテレが見れない！！今のところ、ただの紐、状態。']\n","[1 1 0 ... 0 0 0]\n","Vectorizing...\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.8/dist-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\n"]},{"ename":"KeyboardInterrupt","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-13-4c9181a3c95f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     96\u001b[0m   \u001b[0;31m#main()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-13-4c9181a3c95f>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     73\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Vectorizing...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m   \u001b[0mvectorizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCountVectorizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m   \u001b[0mx_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m   \u001b[0mx_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m   1385\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1386\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1387\u001b[0;31m         \u001b[0mvocabulary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_count_vocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_documents\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfixed_vocabulary_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1388\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1389\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m_count_vocab\u001b[0;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[1;32m   1272\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mraw_documents\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1273\u001b[0m             \u001b[0mfeature_counter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1274\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mfeature\u001b[0m \u001b[0;32min\u001b[0m \u001b[0manalyze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1275\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1276\u001b[0m                     \u001b[0mfeature_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/janome/tokenizer.py\u001b[0m in \u001b[0;36m__tokenize_stream\u001b[0;34m(self, text, wakati, baseform_unk, dotfile)\u001b[0m\n\u001b[1;32m    224\u001b[0m         \u001b[0mprocessed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mprocessed\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mtext_length\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 226\u001b[0;31m             \u001b[0mtokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__tokenize_partial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mprocessed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwakati\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbaseform_unk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdotfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    227\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtokens\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/janome/tokenizer.py\u001b[0m in \u001b[0;36m__tokenize_partial\u001b[0;34m(self, text, wakati, baseform_unk, dotfile)\u001b[0m\n\u001b[1;32m    248\u001b[0m             \u001b[0mentries\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msys_dic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlookup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoded_partial_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatcher\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m                 \u001b[0mlattice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSurfaceNode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNodeType\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSYS_DICT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m             \u001b[0mmatched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentries\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/janome/lattice.py\u001b[0m in \u001b[0;36madd\u001b[0;34m(self, node)\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0mmin_cost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_node\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode_left_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin_cost\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleft_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0mdic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0menode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menodes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m             \u001b[0mcost\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin_cost\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_trans_cost\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mright_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode_left_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcost\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mmin_cost\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["#5-7 モデルの学習と評価\n","\n","#feature_selection\n","from sklearn.feature_extraction.text import CountVectorizer\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.feature_selection import SelectKBest, mutual_info_classif\n","from sklearn.metrics import accuracy_score\n","from sklearn.model_selection import train_test_split\n","\n","#from preprocessing import *\n","#preprocessing.py\n","import re\n","from bs4 import BeautifulSoup\n","!pip install janome\n","from janome.tokenizer import Tokenizer\n","t = Tokenizer()\n","\n","def clean_html(html, strip = False):\n","  soup = BeautifulSoup(html, 'html.parser')\n","  text = soup.get_text(strip = strip)\n","  return text\n","\n","def tokenize(text):\n","  return t.tokenize(text, wakati = True)\n","\n","#from utils import *\n","#utils.py\n","import string\n","import pandas as pd\n","\n","#テキストの英語の割合がthresholdよりも多ければ英語とみなす\n","def filter_by_ascii_rate(text, threshold = 0.9):\n","  ascii_letters = set(string.printable)\n","  rate = sum(c in ascii_letters for c in text) / len(text)\n","  return rate <= threshold\n","\n","def load_dataset(filename, n = 5000, state = 6):                                                    \n","  df = pd.read_csv(filename, sep = '\\t')\n","\n","  #Converts multi-class to binary-class\n","\n","  mapping = {1: 0, 2: 0, 4: 1, 5: 1}\n","  df = df[df.star_rating != 3]\n","  df.star_rating = df.star_rating.map(mapping)\n","\n","  #extract Japanese.txt\n","  is_jp = df.review_body.apply(filter_by_ascii_rate)\n","  df = df[is_jp]\n","\n","  df = df.sample(frac = 1, random_state = state) #shuffle\n","  grouped = df.groupby('star_rating')\n","  df = grouped.head(n=n)\n","  return df.review_body.values, df.star_rating.values\n","\n","def train_and_eval(x_train, y_train, x_test, y_test, vectorizer):\n","  x_train_vec = vectorizer.fit_transform(x_train)\n","  x_test_vec = vectorizer.transform(x_test)\n","  clf = LogisticRegression(solver='liblinear')\n","  clf.fit(x_train_vec, y_train)\n","  y_pred = clf.predict(x_test_vec)\n","  score = accuracy_score(y_test, y_pred)\n","  print('{:.4f}'.format(score))\n","\n","\n","#feature_selection.py\n","def main():\n","  print('Loading...')\n","  x, y = load_dataset('amazon_reviews_multilingual_JP_v1_00.tsv', n = 5000)\n","  print(x)\n","  print(y)\n","  x = [clean_html(text, strip = True) for text in x]   \n","  x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 42)\n","\n","  print('Vectorizing...')\n","  vectorizer = CountVectorizer(tokenizer = tokenize)\n","  x_train = vectorizer.fit_transform(x_train)\n","  x_test = vectorizer.transform(x_test)\n","  print(x_train.shape)\n","  print(x_test.shape)\n","\n","  print('Selecting features...')\n","  selector = SelectKBest(k = 7000, score_func = mutual_info_classif)\n","  selector.fit(x_train, y_train)\n","  x_train_new = selector.transform(x_train)\n","  x_test_new = selector.transform(x_test)\n","  print(x_train_new.shape)\n","  print(x_test_new.shape)\n","\n","  print('Evaluating...')\n","  clf = LogisticRegression(solver = 'liblinear')\n","  clf.fit(x_train_new, y_train)\n","  y_pred = clf.predict(x_test_new)\n","  score = accuracy_score(y_test, y_pred)\n","  print('{:.4f}'.format(score))\n","\n","#if __main__ == '__main__':\n","  #main()\n","\n","main()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":498},"executionInfo":{"elapsed":37596,"status":"error","timestamp":1678276296346,"user":{"displayName":"鈴木慎平","userId":"00141692729728736613"},"user_tz":-540},"id":"rUD3blvzC22g","outputId":"df7b4abf-f7c8-4411-b1c6-cd955941920a"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting janome\n","  Downloading Janome-0.4.2-py2.py3-none-any.whl (19.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.7/19.7 MB\u001b[0m \u001b[31m30.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: janome\n","Successfully installed janome-0.4.2\n"]},{"ename":"KeyboardInterrupt","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-673035ddfb4c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     83\u001b[0m   \u001b[0;31m#main()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-2-673035ddfb4c>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;31m#train.py\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m   \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'amazon_reviews_multilingual_JP_v1_00.tsv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m   \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mclean_html\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrip\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtext\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m   \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-2-673035ddfb4c>\u001b[0m in \u001b[0;36mload_dataset\u001b[0;34m(filename, n, state)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m   \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'\\t'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m   \u001b[0;31m#Converts multi-class to binary-class\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    486\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    487\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 488\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    489\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1057\u001b[0m             \u001b[0mnew_rows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1058\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1059\u001b[0;31m         \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1060\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1061\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_currow\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mnew_rows\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    612\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m             \u001b[0;31m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 614\u001b[0;31m             \u001b[0mmgr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict_to_mgr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtyp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmanager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    615\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMaskedArray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    616\u001b[0m             \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmrecords\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmrecords\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36mdict_to_mgr\u001b[0;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[1;32m    462\u001b[0m         \u001b[0;31m# TODO: can we get rid of the dt64tz special case above?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 464\u001b[0;31m     return arrays_to_mgr(\n\u001b[0m\u001b[1;32m    465\u001b[0m         \u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtyp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtyp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconsolidate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    466\u001b[0m     )\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36marrays_to_mgr\u001b[0;34m(arrays, arr_names, index, columns, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtyp\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"block\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m         return create_block_manager_from_arrays(\n\u001b[0m\u001b[1;32m    136\u001b[0m             \u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marr_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconsolidate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconsolidate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m         )\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mcreate_block_manager_from_arrays\u001b[0;34m(arrays, names, axes, consolidate)\u001b[0m\n\u001b[1;32m   1771\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m         \u001b[0mblocks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_form_blocks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconsolidate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m         \u001b[0mmgr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBlockManager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36m_form_blocks\u001b[0;34m(arrays, names, axes, consolidate)\u001b[0m\n\u001b[1;32m   1860\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1861\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitems_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"ObjectBlock\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1862\u001b[0;31m         object_blocks = _simple_blockify(\n\u001b[0m\u001b[1;32m   1863\u001b[0m             \u001b[0mitems_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"ObjectBlock\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobject_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconsolidate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconsolidate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1864\u001b[0m         )\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36m_simple_blockify\u001b[0;34m(tuples, dtype, consolidate)\u001b[0m\n\u001b[1;32m   1901\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_tuples_to_blocks_no_consolidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtuples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1902\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1903\u001b[0;31m     \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplacement\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_stack_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtuples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1904\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1905\u001b[0m     \u001b[0;31m# TODO: CHECK DTYPE?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36m_stack_arrays\u001b[0;34m(tuples, dtype)\u001b[0m\n\u001b[1;32m   1955\u001b[0m     \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfirst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1956\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1957\u001b[0;31m     \u001b[0mstacked\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1958\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1959\u001b[0m         \u001b[0mstacked\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["#6-2 ロジスティック回帰\n","\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.model_selection import train_test_split, cross_val_score\n","from sklearn.metrics import accuracy_score\n","\n","\n","#from preprocessing import *\n","#preprocessing.py\n","import re\n","from bs4 import BeautifulSoup\n","!pip install janome\n","from janome.tokenizer import Tokenizer\n","t = Tokenizer()\n","\n","def clean_html(html, strip = False):\n","  soup = BeautifulSoup(html, 'html.parser')\n","  text = soup.get_text(strip = strip)\n","  return text\n","\n","def tokenize(text):\n","  return t.tokenize(text, wakati = True)\n","\n","\n","#from utils import *\n","#utils.py\n","import string\n","import pandas as pd\n","\n","#テキストの英語の割合がthresholdよりも多ければ英語とみなす\n","def filter_by_ascii_rate(text, threshold = 0.9):\n","  ascii_letters = set(string.printable)\n","  rate = sum(c in ascii_letters for c in text) / len(text)\n","  return rate <= threshold\n","\n","def load_dataset(filename, n = 5000, state = 6):                                                    \n","  df = pd.read_csv(filename, sep = '\\t')\n","\n","  #Converts multi-class to binary-class\n","\n","  mapping = {1: 0, 2: 0, 4: 1, 5: 1}\n","  df = df[df.star_rating != 3]\n","  df.star_rating = df.star_rating.map(mapping)\n","\n","  #extract Japanese.txt\n","  is_jp = df.review_body.apply(filter_by_ascii_rate)\n","  df = df[is_jp]\n","\n","  df = df.sample(frac = 1, random_state = state) #shuffle\n","  grouped = df.groupby('star_rating')\n","  df = grouped.head(n=n)\n","  return df.review_body.values, df.star_rating.values\n","\n","def train_and_eval(x_train, y_train, x_test, y_test, vectorizer):\n","  x_train_vec = vectorizer.fit_transform(x_train)\n","  x_test_vec = vectorizer.transform(x_test)\n","  clf = LogisticRegression(solver='liblinear')\n","  clf.fit(x_train_vec, y_train)\n","  y_pred = clf.predict(x_test_vec)\n","  score = accuracy_score(y_test, y_pred)\n","  print('{:.4f}'.format(score))\n","\n","\n","#train.py\n","def main():\n","  x, y = load_dataset('amazon_reviews_multilingual_JP_v1_00.tsv', n = 5000)\n","  x = [clean_html(text, strip = True) for text in x]   \n","  x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 42)\n","\n","  vectorizer = TfidfVectorizer(tokenizer = tokenize)\n","  x_train_vec = vectorizer.fit_transform(x_train)\n","  x_test_vec = vectorizer.transform(x_test)\n","\n","  clf = LogisticRegression(solver = 'liblinear')\n","  clf.fit(x_train_vec, y_train)\n","\n","  y_pred = clf.predict(x_test_vec)\n","  score = accuracy_score(y_test, y_pred)\n","  print('Accuracy(test): {:.4f}'.format(score))\n","\n","#if __name__ == '__main__'\n","  #main()\n","\n","main()\n","\n","\n","#cross_validation.py\n","x, y = load_dataset('amazon_reviews_multilingual_JP_v1_00.tsv', n = 5000)\n","x = [clean_html(text, strip = True) for text in x]   \n","x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 42)\n","\n","vectorizer = TfidfVectorizer(tokenizer = tokenize)\n","x_train_vec = vectorizer.fit_transform(x_train)\n","x_test_vec = vectorizer.transform(x_test)\n","\n","clf = LogisticRegression(solver = 'liblinear')\n","scores = cross_val_score(clf, x_train_vec, y_train, cv = 5)\n","print(scores)\n","print('Accuracy: {:.4f} (+/- {:.4f})'.format(scores.mean(), scores.std() * 2))\n","\n","clf.fit(x_train_vec, y_train)\n","y_pred = clf.predict(x_test_vec)\n","score = accuracy_score(y_test, y_pred)\n","print('Accuracy(test): {:.4f}'.format(score))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":386},"executionInfo":{"elapsed":259272,"status":"ok","timestamp":1678278286028,"user":{"displayName":"鈴木慎平","userId":"00141692729728736613"},"user_tz":-540},"id":"4GWcvPlzUvWN","outputId":"7574fc4d-a6f0-4d87-d559-e2468c8ada65"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: janome in /usr/local/lib/python3.8/dist-packages (0.4.2)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.8/dist-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\n"]},{"data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["#6-6 学習曲線\n","\n","#utils.py\n","\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import learning_curve\n","\n","def plot_learning_curve(estimator, title, X, y, ylim = None, cv = None, n_jobs = -1, train_sizes = np.linspace(.1, 1.0, 5)):\n","  plt.figure()\n","  plt.title(title)\n","  if ylim is not None:\n","    plt.ylim(*ylim)\n","  plt.xlabel('Training examples')\n","  plt.ylabel('Score')\n","  train_sizes, train_scores, test_scores = learning_curve(\n","      estimator, X, y, cv = cv, n_jobs = n_jobs, train_sizes = train_sizes\n","  )\n","  train_scores_mean = np.mean(train_scores, axis = 1)\n","  train_scores_std = np.std(train_scores, axis = 1)\n","  test_scores_mean = np.mean(test_scores, axis = 1)\n","  test_scores_std = np.std(test_scores, axis = 1)\n","  plt.grid()\n","\n","  plt.fill_between(train_sizes, train_scores_mean - train_scores_std, train_scores_mean + train_scores_std, alpha = 0.1, color = 'r')\n","  plt.fill_between(train_sizes, test_scores_mean - test_scores_std, test_scores_mean + test_scores_std, alpha = 0.1, color = 'g')\n","  plt.plot(train_sizes, train_scores_mean, 'o-', color = 'r', label = 'Training score')\n","  plt.plot(train_sizes, test_scores_mean, 'o-', color = 'g', label = 'Cross-validation score')\n","\n","  plt.legend(loc = 'best')\n","\n","  plt.show()\n","\n","#learning_curve.py\n","\n","from sklearn.model_selection import ShuffleSplit\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.model_selection import train_test_split\n","\n","#from preprocessing import *\n","#preprocessing.py\n","import re\n","from bs4 import BeautifulSoup\n","!pip install janome\n","from janome.tokenizer import Tokenizer\n","t = Tokenizer()\n","\n","def clean_html(html, strip = False):\n","  soup = BeautifulSoup(html, 'html.parser')\n","  text = soup.get_text(strip = strip)\n","  return text\n","\n","def tokenize(text):\n","  return t.tokenize(text, wakati = True)\n","\n","#from utils import *\n","\n","def main():\n","  x, y = load_dataset('amazon_reviews_multilingual_JP_v1_00.tsv', n = 5000)\n","  x = [clean_html(text, strip = True) for text in x]   \n","  x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 42)\n","\n","  vectorizer = TfidfVectorizer(tokenizer = tokenize)\n","  x_train_vec = vectorizer.fit_transform(x_train)\n","  x_test_vec = vectorizer.transform(x_test)\n","\n","  title = 'Learning Curves'\n","  cv = ShuffleSplit(n_splits = 5, test_size = 0.2, random_state = 0)\n","  clf = LogisticRegression(solver = 'liblinear')\n","  plot_learning_curve(clf, title, x_train_vec, y_train, cv = cv)\n","\n","main()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":800647,"status":"ok","timestamp":1678292551638,"user":{"displayName":"鈴木慎平","userId":"00141692729728736613"},"user_tz":-540},"id":"BJ2aM08-JcuP","outputId":"77d0c5ea-68b8-4e25-8f21-899479f1f0b3"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: janome in /usr/local/lib/python3.8/dist-packages (0.4.2)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.8/dist-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["Accuracy(test): 0.8440\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.8/dist-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["{'C': 3, 'penalty': 'l2'}\n","Accuracy(best): 0.8332\n","Accuracy_score(test): 0.8540\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.8/dist-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["Accuracy(test): 0.8440\n"]}],"source":["#6-8 ハイパーパラメータチューニング\n","\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score\n","from sklearn.model_selection import GridSearchCV \n","\n","\n","#from preprocessing import *\n","#preprocessing.py\n","import re\n","from bs4 import BeautifulSoup\n","!pip install janome\n","from janome.tokenizer import Tokenizer\n","t = Tokenizer()\n","\n","def clean_html(html, strip = False):\n","  soup = BeautifulSoup(html, 'html.parser')\n","  text = soup.get_text(strip = strip)\n","  return text\n","\n","def tokenize(text):\n","  return t.tokenize(text, wakati = True)\n","\n","\n","#from utils import *\n","#utils.py\n","import string\n","import pandas as pd\n","\n","#テキストの英語の割合がthresholdよりも多ければ英語とみなす\n","def filter_by_ascii_rate(text, threshold = 0.9):\n","  ascii_letters = set(string.printable)\n","  rate = sum(c in ascii_letters for c in text) / len(text)\n","  return rate <= threshold\n","\n","def load_dataset(filename, n = 5000, state = 6):                                                    \n","  df = pd.read_csv(filename, sep = '\\t')\n","\n","  #Converts multi-class to binary-class\n","\n","  mapping = {1: 0, 2: 0, 4: 1, 5: 1}\n","  df = df[df.star_rating != 3]\n","  df.star_rating = df.star_rating.map(mapping)\n","\n","  #extract Japanese.txt\n","  is_jp = df.review_body.apply(filter_by_ascii_rate)\n","  df = df[is_jp]\n","\n","  df = df.sample(frac = 1, random_state = state) #shuffle\n","  grouped = df.groupby('star_rating')\n","  df = grouped.head(n=n)\n","  return df.review_body.values, df.star_rating.values\n","\n","def train_and_eval(x_train, y_train, x_test, y_test, vectorizer):\n","  x_train_vec = vectorizer.fit_transform(x_train)\n","  x_test_vec = vectorizer.transform(x_test)\n","  clf = LogisticRegression(solver='liblinear')\n","  clf.fit(x_train_vec, y_train)\n","  y_pred = clf.predict(x_test_vec)\n","  score = accuracy_score(y_test, y_pred)\n","  print('{:.4f}'.format(score))\n","\n","\n","#hp_optimization.py\n","x, y = load_dataset('amazon_reviews_multilingual_JP_v1_00.tsv', n = 5000)\n","x = [clean_html(text, strip = True) for text in x]   \n","x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 42)\n","\n","vectorizer = TfidfVectorizer(tokenizer = tokenize)\n","x_train_vec = vectorizer.fit_transform(x_train)\n","x_test_vec = vectorizer.transform(x_test)\n","\n","parameters = {'penalty': ['l1', 'l2'], 'C': [0.01, 0.03, 0.1, 0.3, 0.7, 1, 1.01, 1.03, 1.07, 1.1, 1.3, 1.7, 3]}\n","lr = LogisticRegression(solver = 'liblinear')\n","clf = GridSearchCV(lr, parameters, cv = 5, n_jobs = -1)\n","clf.fit(x_train_vec, y_train)\n","\n","best_clf = clf.best_estimator_\n","print(clf.best_params_)\n","print('Accuracy(best): {:.4f}'.format(clf.best_score_))\n","y_pred = best_clf.predict(x_test_vec)\n","score = accuracy_score(y_test, y_pred)\n","print('Accuracy_score(test): {:.4f}'.format(score))\n","\n","main()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":297},"executionInfo":{"elapsed":1321,"status":"ok","timestamp":1678328966143,"user":{"displayName":"鈴木慎平","userId":"00141692729728736613"},"user_tz":-540},"id":"Wk7xrUYv-k7y","outputId":"0ac2520b-f696-491c-e585-3956eed1b971"},"outputs":[{"data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 2 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["#7-3 ニューラルネットワーク バイアス\n","\n","import matplotlib.pyplot as plt\n","import numpy as np\n","\n","x = np.arange(-6, 6, 0.1)\n","weights = [0.5, 1.0, 2.0]\n","for i, w in enumerate(weights):\n","  f = 1 / (1 + np.exp(-x * w))\n","  label = 'w{} = {}'.format(i, w)\n","  plt.subplot(1, 2, 1)\n","  plt.plot(x, f, label = label)\n","plt.xlabel('x')\n","plt.ylabel('y')\n","plt.legend(loc = 2)\n","\n","w = 5\n","biases = [-8.0, 0, 8.0]\n","for i, b in enumerate(biases):\n","  f = 1 / (1 + np.exp(-x * w + b))\n","  label = 'b{} = {}'.format(i, b)\n","  plt.subplot(1, 2, 2)\n","  plt.plot(x, f, label = label)\n","plt.xlabel('x')\n","plt.ylabel('y')\n","plt.legend(loc = 2)\n","\n","plt.tight_layout()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":491,"status":"ok","timestamp":1678329808122,"user":{"displayName":"鈴木慎平","userId":"00141692729728736613"},"user_tz":-540},"id":"wAq0v8ZvLOBl","outputId":"1f69cf72-d8c9-4772-b21c-299b6a82807f"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"model\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_1 (InputLayer)        [(None, 16)]              0         \n","                                                                 \n"," dense_10 (Dense)            (None, 32)                544       \n","                                                                 \n"," dense_11 (Dense)            (None, 5)                 165       \n","                                                                 \n","=================================================================\n","Total params: 709\n","Trainable params: 709\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}],"source":["#7-5 Kerasによるニューラルネットワーク\n","\n","#Sequential\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense\n","model = Sequential()\n","model.add(Dense(units= 32, activation = 'relu', input_shape = (16,)))\n","model.add(Dense(units = 5, activation = 'softmax'))\n","\n","inputs = np.ones((1, 16), dtype = np.float32)\n","model (inputs)\n","\n","#Functutional API\n","from tensorflow.keras.layers import Input, Dense\n","from tensorflow.keras.models import Model\n","x = Input(shape = (16,))\n","h = Dense(units = 32, activation = 'relu')(x)\n","y = Dense(units = 5, activation = 'softmax')(h)\n","model = Model(inputs = [x], outputs = [y])\n","\n","model.summary()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":877},"executionInfo":{"elapsed":356923,"status":"ok","timestamp":1678499925231,"user":{"displayName":"鈴木慎平","userId":"00141692729728736613"},"user_tz":-540},"id":"c1lf0PJRo66d","outputId":"a51b0117-1a2f-4836-8b44-13c9db23952e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: janome in /usr/local/lib/python3.9/dist-packages (0.4.2)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.9/dist-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 1/100\n","200/200 [==============================] - 6s 25ms/step - loss: 0.5236 - accuracy: 0.7809 - val_loss: 0.4315 - val_accuracy: 0.8300\n","Epoch 2/100\n","200/200 [==============================] - 6s 28ms/step - loss: 0.2648 - accuracy: 0.9183 - val_loss: 0.4270 - val_accuracy: 0.8300\n","Epoch 3/100\n","200/200 [==============================] - 4s 22ms/step - loss: 0.1450 - accuracy: 0.9656 - val_loss: 0.4340 - val_accuracy: 0.8375\n","Epoch 4/100\n","200/200 [==============================] - 4s 20ms/step - loss: 0.0836 - accuracy: 0.9847 - val_loss: 0.4788 - val_accuracy: 0.8319\n","Epoch 5/100\n","200/200 [==============================] - 5s 26ms/step - loss: 0.0479 - accuracy: 0.9934 - val_loss: 0.5271 - val_accuracy: 0.8238\n","1/1 [==============================] - 0s 124ms/step\n","[[0.33710438 0.66289556]]\n"]},{"data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{},"output_type":"display_data"},{"data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["#実践\n","\n","\n","#model.py\n","\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense\n","\n","def create_model(vocab_size, label_size, hidden_size = 16):\n","  model = Sequential()\n","  model.add(Dense(hidden_size, activation = 'relu', input_shape = (vocab_size,)))\n","  model.add(Dense(label_size, activation = 'softmax'))\n","  return model\n","\n","\n","#Sequenceクラスを使う場合のクラス定義\n","\n","import math\n","from tensorflow.keras.utils import Sequence\n","\n","class Generator(Sequence):\n","\n","  def __init__(self, x, y, batch_size = 32):\n","    self.x = x\n","    self.y = y\n","    self.batch_size = batch_size\n","\n","  def __getitem__(self, idx):\n","    batch_x = self.x[idx * self.batch_size: (idx + 1) * self.batch_size]\n","    batch_y = self.y[idx * self.batch_size: (idx + 1) * self.batch_size]\n","    return batch_x, batch_y\n","\n","  def __len__(self):\n","    return math.ceil(len(self.x) / self.batch_size)\n","\n","\n","#from preprocessing import *\n","#preprocessing.py\n","import re\n","from bs4 import BeautifulSoup\n","!pip install janome\n","from janome.tokenizer import Tokenizer\n","t = Tokenizer()\n","\n","def clean_html(html, strip = False):\n","  soup = BeautifulSoup(html, 'html.parser')\n","  text = soup.get_text(strip = strip)\n","  return text\n","\n","def tokenize(text):\n","  return t.tokenize(text, wakati = True)\n","\n","\n","#from utils import *\n","#utils.py\n","import string\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","\n","#テキストの英語の割合がthresholdよりも多ければ英語とみなす\n","def filter_by_ascii_rate(text, threshold = 0.9):\n","  ascii_letters = set(string.printable)\n","  rate = sum(c in ascii_letters for c in text) / len(text)\n","  return rate <= threshold\n","\n","def load_dataset(filename, n = 5000, state = 6):                                                    \n","  df = pd.read_csv(filename, sep = '\\t')\n","\n","  #Converts multi-class to binary-class\n","  mapping = {1: 0, 2: 0, 4: 1, 5: 1}\n","  df = df[df.star_rating != 3]\n","  df.star_rating = df.star_rating.map(mapping)\n","\n","  #extract Japanese text\n","  is_jp = df.review_body.apply(filter_by_ascii_rate)\n","  df = df[is_jp]\n","\n","  #sampling\n","  df = df.sample(frac = 1, random_state = state) #shuffle\n","  grouped = df.groupby('star_rating')\n","  df = grouped.head(n=n)\n","  return df.review_body.values, df.star_rating.values\n","\n","def train_and_eval(x_train, y_train, x_test, y_test, vectorizer):\n","  x_train_vec = vectorizer.fit_transform(x_train)\n","  x_test_vec = vectorizer.transform(x_test)\n","  clf = LogisticRegression(solver='liblinear')\n","  clf.fit(x_train_vec, y_train)\n","  y_pred = clf.predict(x_test_vec)\n","  score = accuracy_score(y_test, y_pred)\n","  print('{:.4f}'.format(score))\n","\n","def plot_history(history):\n","  #Setting\n","  loss = history.history['loss']\n","  val_loss = history.history['val_loss']\n","  acc = history.history['accuracy']\n","  val_acc = history.history['val_accuracy']\n","  epochs = range(1, len(loss) + 1)\n","\n","  #Plotting loss\n","  plt.plot(epochs, loss, 'r', label = 'Training loss')\n","  plt.plot(epochs, val_loss, 'b', label = 'Validation loss')\n","  plt.title('Training and validation loss')\n","  plt.xlabel('Epochs')\n","  plt.ylabel('Loss')\n","  plt.legend()\n","\n","  plt.figure()\n","\n","  #Plotting accuracy\n","  plt.plot(epochs, acc, 'r', label = 'Training acc')\n","  plt.plot(epochs, val_acc, 'b', label = 'Validation acc')\n","  plt.title('Training and validation accuracy')\n","  plt.xlabel('Epochs')\n","  plt.ylabel('Accuracy')\n","  plt.legend()\n","\n","  plt.show()\n","\n","\n","#train.py\n","\n","from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, TensorBoard\n","from tensorflow.keras.models import load_model\n","from sklearn.feature_extraction.text import CountVectorizer\n","from sklearn.model_selection import train_test_split\n","\n","#from model import create_model\n","#from preprocessing import *\n","#from utils import *\n","\n","def main():\n","  #データセットの読み込み\n","  x, y = load_dataset('amazon_reviews_multilingual_JP_v1_00.tsv', n = 5000)\n","  x = [clean_html(text, strip = True) for text in x]   \n","  x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 42)\n","\n","  vectorizer = CountVectorizer(tokenizer = tokenize)\n","  x_train = vectorizer.fit_transform(x_train)\n","  x_test = vectorizer.transform(x_test)\n","  x_train = x_train.toarray()\n","  x_test = x_test.toarray()\n","\n","  #ハイパーパラメータの設定\n","  vocab_size = len(vectorizer.vocabulary_)\n","  label_size = len(set(y_train))\n","\n","  #モデルの構築\n","  model = create_model(vocab_size, label_size)\n","  model.compile(loss = 'sparse_categorical_crossentropy',\n","                optimizer = 'adam',\n","                metrics = ['accuracy'])\n","  \n","  #コールバックの準備\n","  filepath = 'model.h5'\n","  callbacks = [\n","      EarlyStopping(patience = 3),\n","      ModelCheckpoint(filepath, save_best_only = True),\n","      TensorBoard(log_dir = 'logs')\n","  ]\n","\n","  #モデルの学習\n","  history = model.fit(x_train, y_train, validation_split = 0.2, epochs = 100, batch_size = 32, callbacks = callbacks)\n","  \n","  #モデルの読み込み\n","  model = load_model(filepath)\n","\n","  #モデルを使った予測\n","  text = 'このアプリ最高!'\n","  vec = vectorizer.transform([text])\n","  y_pred = model.predict(vec.toarray())\n","  print(y_pred)\n","\n","  #正解率と損失のグラフの描画\n","  plot_history(history)\n","\n","main()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":241,"status":"ok","timestamp":1678581793638,"user":{"displayName":"鈴木慎平","userId":"00141692729728736613"},"user_tz":-540},"id":"nZixEjHYbjAT","outputId":"ab37fc0b-44d0-4b4f-fa3f-814b73b4e3b4"},"outputs":[{"name":"stdout","output_type":"stream","text":["['今日 は 良い 天気 だ 。 あらら 良い 日 ですこと 。']\n","[['今日 は 良い 天気 だ 。 あらら 良い 日 ですこと 。']]\n","{'<UNK>': 1, '良い': 2, '。': 3, '今日': 4, 'は': 5, '天気': 6, 'だ': 7, 'あらら': 8, '日': 9, 'ですこと': 10}\n","{1: '<UNK>', 2: '良い', 3: '。', 4: '今日', 5: 'は', 6: '天気', 7: 'だ', 8: 'あらら', 9: '日', 10: 'ですこと'}\n","[[4, 5, 2, 6, 7, 3, 8, 2, 9, 10, 3]]\n"]}],"source":["from tensorflow.keras. preprocessing.text import Tokenizer\n","tokenizer = Tokenizer(num_words = 20, oov_token = '<UNK>')\n","texts = ['今日 は 良い 天気 だ 。 あらら 良い 日 ですこと 。']\n","tokenizer.fit_on_texts(texts)\n","print(tokenizer.word_index)\n","print(tokenizer.index_word)\n","print(tokenizer.texts_to_sequences(texts))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":359,"status":"ok","timestamp":1678581551627,"user":{"displayName":"鈴木慎平","userId":"00141692729728736613"},"user_tz":-540},"id":"Nin7na5IcxK_","outputId":"0c9d8140-2c4a-4c3e-bcbf-3ea244003ee5"},"outputs":[{"name":"stdout","output_type":"stream","text":["([['猫', 'は'],\n","  ['かわいい', 3],\n","  ['は', 'かわいい'],\n","  ['猫', 3],\n","  ['は', 3],\n","  ['かわいい', 'は'],\n","  ['は', '猫'],\n","  ['は', 2]],\n"," [1, 0, 1, 0, 0, 1, 1, 0])\n"]}],"source":["from pprint import pprint\n","from tensorflow.keras.preprocessing.sequence import skipgrams\n","sequence = ['猫', 'は', 'かわいい']\n","pprint(skipgrams(sequence, vocabulary_size = 4, window_size = 1))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ackVxJNIw2pf","outputId":"62fcab88-bee0-4853-f69c-79badcda9dc5"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/10\n","59582/59582 [==============================] - ETA: 0s - loss: 0.2379"]},{"name":"stderr","output_type":"stream","text":["WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"]},{"name":"stdout","output_type":"stream","text":["59582/59582 [==============================] - 951s 16ms/step - loss: 0.2379 - val_loss: 0.2020\n","Epoch 2/10\n","59580/59582 [============================>.] - ETA: 0s - loss: 0.1821"]},{"name":"stderr","output_type":"stream","text":["WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"]},{"name":"stdout","output_type":"stream","text":["59582/59582 [==============================] - 1194s 20ms/step - loss: 0.1821 - val_loss: 0.1861\n","Epoch 3/10\n","59579/59582 [============================>.] - ETA: 0s - loss: 0.1655"]},{"name":"stderr","output_type":"stream","text":["WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"]},{"name":"stdout","output_type":"stream","text":["59582/59582 [==============================] - 1075s 18ms/step - loss: 0.1655 - val_loss: 0.1790\n","Epoch 4/10\n","59582/59582 [==============================] - ETA: 0s - loss: 0.1559"]},{"name":"stderr","output_type":"stream","text":["WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"]},{"name":"stdout","output_type":"stream","text":["59582/59582 [==============================] - 864s 15ms/step - loss: 0.1559 - val_loss: 0.1768\n","Epoch 5/10\n","59581/59582 [============================>.] - ETA: 0s - loss: 0.1493"]},{"name":"stderr","output_type":"stream","text":["WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"]},{"name":"stdout","output_type":"stream","text":["59582/59582 [==============================] - 833s 14ms/step - loss: 0.1493 - val_loss: 0.1744\n","Epoch 6/10\n","59581/59582 [============================>.] - ETA: 0s - loss: 0.1443"]},{"name":"stderr","output_type":"stream","text":["WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"]},{"name":"stdout","output_type":"stream","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r59582/59582 [==============================] - 862s 14ms/step - loss: 0.1443 - val_loss: 0.1711\n","Epoch 7/10\n","39612/59582 [==================>...........] - ETA: 4:42 - loss: 0.1398"]}],"source":["#8-4 単語分散表現 モデルの実装\n","\n","#utils.py\n","def load_data(filepath, encoding = 'utf-8'):\n","  with open(filepath, encoding = encoding) as f:\n","    return f.read()\n","\n","\n","#preprocessing.py\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","\n","def build_vocabulary(text, num_words = None):\n","  tokenizer = Tokenizer(num_words = num_words, oov_token = '<UNK>')\n","  tokenizer.fit_on_texts([text])\n","  return tokenizer\n","\n","import numpy as np\n","from tensorflow.keras.preprocessing.sequence import skipgrams, make_sampling_table\n","\n","def create_dataset(text, vocab, num_words, window_size, negative_samples):\n","  data = vocab.texts_to_sequences([text]).pop()\n","  sampling_table = make_sampling_table(num_words)\n","  couples, labels = skipgrams(data, num_words, window_size = window_size, negative_samples = negative_samples, sampling_table = sampling_table)\n","  word_target, word_context = zip(*couples)\n","  word_target = np.reshape(word_target, (-1, 1))\n","  word_context = np.reshape(word_context, (-1, 1))\n","  labels = np.asarray(labels)\n","  return [word_target, word_context], labels\n","\n","\n","#model.py\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import Input, Dot, Flatten, Embedding, Dense\n","\n","class EmbeddingModel:\n","\n","  def __init__(self, vocab_size, emb_dim = 100):\n","    self.word_input = Input(shape = (1,), name = 'word_input')\n","    self.word_embed = Embedding(input_dim = vocab_size, output_dim = emb_dim, input_length = 1, name = 'word_embedding')\n","\n","    self.context_input = Input(shape = (1,), name = 'context_input')\n","    self.context_embed = Embedding(input_dim = vocab_size, output_dim = emb_dim, input_length = 1, name = 'context_embedding')\n","\n","    self.dot = Dot(axes = 2)\n","    self.flatten = Flatten()\n","    self.output = Dense(1, activation = 'sigmoid')\n","\n","  def build(self):\n","    word_embed = self.word_embed(self.word_input)\n","    context_embed = self.context_embed(self.context_input)\n","    dot = self.dot([word_embed, context_embed])\n","    flatten = self.flatten(dot)\n","    output = self.output(flatten)\n","    model = Model(inputs = [self.word_input, self.context_input], outputs = output)\n","    return model\n","\n","#inference.py\n","from scipy.spatial.distance import cosine\n","from sklearn.metrics.pairwise import cosine_similarity\n","\n","class InferenceAPI:\n","\n","  def __init__(self, model, vocab):\n","    self.vocab = vocab\n","    self.weights = model.get_layer('word_embedding').get_weights()[0]\n","\n","  def most_similar(self, word, topn = 10):\n","    word_index = self.vocab.word_index.get(word, 1)\n","    sim = self._cosine_similarity(word_index)\n","    pairs = [(s, i) for i, s in enumerate(sim)]\n","    pairs.sort(reverse = True)\n","    pairs = pairs[1: topn + 1]\n","    res = [(self.vocab.index_word[i], s) for s, i in pairs]\n","    return res\n","\n","  def similarity(self, word1, word2):\n","    word_index1 = self.vocab.word_index.get(word1, 1)\n","    word_index2 = self.vocab.word_index.get(word2, 1)\n","    weight1 = self.weights[word_index1]\n","    weight2 = self.weights[word_index2]\n","    return cosine(weight1, weight2)\n","\n","  def _cosine_similarity(self, target_idx):\n","    target_weight = self.weights[target_idx]\n","    similarity = cosine_similarity(self.weights, [target_weight])\n","    return similarity.flatten()\n","\n","\n","#train.py\n","from pprint import pprint\n","\n","from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n","from tensorflow.keras.models import load_model\n","\n","#from interfence import InterfenceAPI\n","#from model import EmbeddingModel\n","#from preprocessing import build_vocabulary, create_dataset\n","#from utils import load_data\n","\n","#if __name__ == '__main__':\n","#ハイパーパラメータの設定\n","emb_dim = 50\n","epochs = 10\n","model_path = 'model.5h'\n","negative_samples = 1\n","num_words = 10000\n","window_size = 1\n","\n","#コーパスの読み込み\n","text = load_data(filepath = 'ja.text8')\n","\n","#ボキャブラリの構築\n","vocab = build_vocabulary(text, num_words)\n","\n","#データセットの作成\n","x, y = create_dataset(text, vocab, num_words, window_size, negative_samples)\n","\n","#モデルの構築\n","model = EmbeddingModel(num_words, emb_dim)\n","model = model.build()\n","model.compile(optimizer = 'adam', loss = 'binary_crossentropy')\n","\n","#コールバックの用意\n","callbacks = [\n","    EarlyStopping(patience = 1),\n","    ModelCheckpoint(model_path, save_best_only = True),\n","]\n","\n","#モデルの学習\n","model.fit(x = x, y = y, batch_size = 128, epochs = epochs, validation_split = 0.2, callbacks = callbacks)\n","\n","#予測\n","model = load_model(model_path)\n","api = InferenceAPI(model, vocab)\n","pprint(api.most_similar(word = '日本'))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":123895,"status":"ok","timestamp":1678611273504,"user":{"displayName":"鈴木慎平","userId":"00141692729728736613"},"user_tz":-540},"id":"kNQV1lRia7PE","outputId":"f3e8960a-0050-4f6e-fad6-8d7f6ceaefc7"},"outputs":[{"name":"stdout","output_type":"stream","text":["[ 0.08435152  0.28150475  0.05168748  0.31487155  0.07147881 -0.3180124\n"," -0.32322782  0.52504814 -0.33750683  0.07085347  0.5384826   0.1790357\n","  0.2531912   0.06290261  0.24126692 -0.5253487   0.11321679 -0.50769967\n"," -0.5536639  -0.09628688  0.14732493 -0.40847343  0.37408844  0.09026558\n"," -0.01811778  0.4239788  -0.30526856  0.2075222  -0.35493806  0.21895035\n"," -0.30948833  0.1515916   0.43833813 -0.523335   -0.21589346  0.90868217\n","  0.03655175  0.45846257 -0.02861794  0.52233505  0.48537284  0.30766678\n"," -0.49978638  0.70742935 -0.20985132  0.19354488 -0.16501573 -0.38596177\n","  0.23882268  0.20238556  0.0674374  -0.5201858   0.19065113 -0.06345396\n","  0.1819109  -0.2562319   0.12998848  0.4155867  -0.3870898   0.19400619\n"," -0.40075192 -0.25519803 -0.33186752 -0.17284892 -0.27950072  0.10670578\n"," -0.28924102  0.0274303   0.10702149 -0.33575985  0.28257003  0.08694525\n"," -0.07076725 -0.49772897  0.08539782  0.14016114  0.21407987  0.15183572\n"," -0.41099542 -0.08981933 -0.01230178  0.21032953  0.02474365 -0.38615844\n"," -0.46207565  0.15311931 -0.01415277 -0.31663734  0.40730366 -0.07851864\n","  0.11005522  0.08470042 -0.2441676   0.01237891  0.16821492 -0.0291995\n"," -0.43841085  0.47008398  0.10464118 -0.1345646 ]\n","(100,)\n","[('キツネ', 0.7571040391921997), ('野良猫', 0.7517517805099487), ('ネズミ', 0.7494117021560669), ('オオカミ', 0.7456055283546448), ('ブタ', 0.7416437864303589), ('ネコ', 0.739361584186554), ('金魚', 0.7370405197143555), ('ガエル', 0.7262976169586182), ('小鳥', 0.7260740995407104), ('妖精', 0.7226870059967041)]\n","[('イギリス', 0.7247284650802612), ('オーストラリア', 0.7102848291397095), ('アメリカ', 0.6996741890907288), ('ヨーロッパ', 0.6969237327575684), ('カナダ', 0.6784939169883728), ('ノルウェー', 0.6640626788139343), ('英国', 0.652152419090271), ('米国', 0.64627605676651), ('オランダ', 0.637431263923645), ('ブラジル', 0.637090802192688)]\n","0.6158515\n","0.18694103\n","0.7234669\n"]},{"name":"stderr","output_type":"stream","text":["<ipython-input-6-9e0d6bb74dbb>:17: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n","  print(model['猫'])\n","<ipython-input-6-9e0d6bb74dbb>:18: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n","  print(model['猫'].shape)\n","<ipython-input-6-9e0d6bb74dbb>:20: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n","  print(model.most_similar('猫', topn = 10))\n","<ipython-input-6-9e0d6bb74dbb>:22: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n","  print(model.most_similar(positive = ['ロンドン', '日本'], negative = ['東京'], topn = 10))\n","<ipython-input-6-9e0d6bb74dbb>:24: DeprecationWarning: Call to deprecated `similarity` (Method will be removed in 4.0.0, use self.wv.similarity() instead).\n","  print(model.similarity('猫', '犬'))\n","<ipython-input-6-9e0d6bb74dbb>:25: DeprecationWarning: Call to deprecated `similarity` (Method will be removed in 4.0.0, use self.wv.similarity() instead).\n","  print(model.similarity('猫', '車'))\n","<ipython-input-6-9e0d6bb74dbb>:26: DeprecationWarning: Call to deprecated `similarity` (Method will be removed in 4.0.0, use self.wv.similarity() instead).\n","  print(model.similarity('セダン', '車'))\n"]}],"source":["#8-5 gensimを使った単語分散表現\n","#!pip install gensim\n","\n","import logging #ログ出力用\n","from gensim.models.word2vec import Word2Vec, Text8Corpus #学習モデルとコーパス読み込み用\n","\n","logging.basicConfig(format = '%(asctime)s : %(levelname)s', level = logging.INFO) #ログを有効にする\n","\n","sentences = Text8Corpus('ja.text8') #コーパス読み込み\n","\n","model = Word2Vec(sentences, size = 100, window = 5, sg = 1) #skip-gramで学習\n","\n","model.save('models/model.bin')\n","\n","model = Word2Vec.load('models/model.bin')\n","\n","print(model['猫'])\n","print(model['猫'].shape)\n","\n","print(model.most_similar('猫', topn = 10))\n","\n","print(model.most_similar(positive = ['ロンドン', '日本'], negative = ['東京'], topn = 10))\n","\n","print(model.similarity('猫', '犬'))\n","print(model.similarity('猫', '車'))\n","print(model.similarity('セダン', '車'))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":678009,"status":"ok","timestamp":1678612903403,"user":{"displayName":"鈴木慎平","userId":"00141692729728736613"},"user_tz":-540},"id":"v91XdHiMaeaM","outputId":"e9a18cf4-f4b4-4de1-da20-5ded178cce6c"},"outputs":[{"name":"stdout","output_type":"stream","text":["--2023-03-12 09:10:25--  https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.ja.300.vec.gz\n","Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 104.22.74.142, 172.67.9.4, 104.22.75.142, ...\n","Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|104.22.74.142|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 1279641604 (1.2G) [binary/octet-stream]\n","Saving to: ‘cc.ja.300.vec.gz’\n","\n","cc.ja.300.vec.gz    100%[===================>]   1.19G  41.5MB/s    in 32s     \n","\n","2023-03-12 09:10:57 (38.3 MB/s) - ‘cc.ja.300.vec.gz’ saved [1279641604/1279641604]\n","\n","[('キツネ', 0.7571040391921997), ('野良猫', 0.7517517805099487), ('ネズミ', 0.7494117021560669), ('オオカミ', 0.7456055283546448), ('ブタ', 0.7416437864303589), ('ネコ', 0.739361584186554), ('金魚', 0.7370405197143555), ('ガエル', 0.7262976169586182), ('小鳥', 0.7260740995407104), ('妖精', 0.7226870059967041)]\n"]},{"name":"stderr","output_type":"stream","text":["<ipython-input-7-9661731cd35c>:8: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n","  print(model.most_similar('猫', topn = 10))\n"]}],"source":["#8-6 学習済み単語分散表現の利用 GloVe\n","\n","!wget https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.ja.300.vec.gz\n","\n","import gensim\n","models = gensim.models.KeyedVectors.load_word2vec_format('cc.ja.300.vec.gz', binary = False)\n","\n","print(model.most_similar('猫', topn = 10))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2824,"status":"ok","timestamp":1678613149460,"user":{"displayName":"鈴木慎平","userId":"00141692729728736613"},"user_tz":-540},"id":"jzNY2rL5bWHw","outputId":"734c7e86-313a-4a2d-faf6-29911a2b492c"},"outputs":[{"name":"stderr","output_type":"stream","text":["<ipython-input-10-8ef85bf7f892>:9: DeprecationWarning: Call to deprecated `evaluate_word_pairs` (Method will be removed in 4.0.0, use self.wv.evaluate_word_pairs() instead).\n","  print(model.evaluate_word_pairs(datapath('wordsim353.tsv'))) #人間との相関の評価\n"]},{"name":"stdout","output_type":"stream","text":["(PearsonRResult(statistic=0.2523995818592843, pvalue=0.0022734567236445736), SignificanceResult(statistic=0.28519969155984304, pvalue=0.0005305956092972414), 59.20679886685553)\n"]},{"name":"stderr","output_type":"stream","text":["<ipython-input-10-8ef85bf7f892>:10: DeprecationWarning: Call to deprecated `accuracy` (Method will be removed in 4.0.0, use self.wv.evaluate_word_analogies() instead).\n","  print(model.accuracy(datapath('questions-words.txt'))) #アナロジーの評価\n"]},{"name":"stdout","output_type":"stream","text":["[{'section': 'capital-common-countries', 'correct': [], 'incorrect': [('LONDON', 'ENGLAND', 'PARIS', 'FRANCE'), ('LONDON', 'ENGLAND', 'TOKYO', 'JAPAN'), ('PARIS', 'FRANCE', 'TOKYO', 'JAPAN'), ('PARIS', 'FRANCE', 'LONDON', 'ENGLAND'), ('TOKYO', 'JAPAN', 'LONDON', 'ENGLAND'), ('TOKYO', 'JAPAN', 'PARIS', 'FRANCE')]}, {'section': 'capital-world', 'correct': [], 'incorrect': [('LONDON', 'ENGLAND', 'PARIS', 'FRANCE'), ('PARIS', 'FRANCE', 'TOKYO', 'JAPAN')]}, {'section': 'currency', 'correct': [], 'incorrect': []}, {'section': 'city-in-state', 'correct': [], 'incorrect': []}, {'section': 'family', 'correct': [], 'incorrect': [('BOY', 'GIRL', 'HE', 'SHE'), ('BOY', 'GIRL', 'KING', 'QUEEN'), ('BOY', 'GIRL', 'MAN', 'WOMAN'), ('HE', 'SHE', 'KING', 'QUEEN'), ('HE', 'SHE', 'MAN', 'WOMAN'), ('HE', 'SHE', 'BOY', 'GIRL'), ('KING', 'QUEEN', 'MAN', 'WOMAN'), ('KING', 'QUEEN', 'BOY', 'GIRL'), ('KING', 'QUEEN', 'HE', 'SHE'), ('MAN', 'WOMAN', 'BOY', 'GIRL'), ('MAN', 'WOMAN', 'HE', 'SHE'), ('MAN', 'WOMAN', 'KING', 'QUEEN')]}, {'section': 'gram1-adjective-to-adverb', 'correct': [], 'incorrect': []}, {'section': 'gram2-opposite', 'correct': [], 'incorrect': []}, {'section': 'gram3-comparative', 'correct': [], 'incorrect': []}, {'section': 'gram4-superlative', 'correct': [], 'incorrect': []}, {'section': 'gram5-present-participle', 'correct': [], 'incorrect': []}, {'section': 'gram6-nationality-adjective', 'correct': [], 'incorrect': [('ENGLAND', 'ENGLISH', 'JAPAN', 'JAPANESE'), ('JAPAN', 'JAPANESE', 'ENGLAND', 'ENGLISH')]}, {'section': 'gram7-past-tense', 'correct': [], 'incorrect': []}, {'section': 'gram8-plural', 'correct': [], 'incorrect': [('DREAM', 'DREAMS', 'EYE', 'EYES'), ('DREAM', 'DREAMS', 'MAN', 'MEN'), ('DREAM', 'DREAMS', 'WOMAN', 'WOMEN'), ('EYE', 'EYES', 'MAN', 'MEN'), ('EYE', 'EYES', 'WOMAN', 'WOMEN'), ('EYE', 'EYES', 'DREAM', 'DREAMS'), ('MAN', 'MEN', 'WOMAN', 'WOMEN'), ('MAN', 'MEN', 'DREAM', 'DREAMS'), ('MAN', 'MEN', 'EYE', 'EYES'), ('WOMAN', 'WOMEN', 'DREAM', 'DREAMS'), ('WOMAN', 'WOMEN', 'EYE', 'EYES'), ('WOMAN', 'WOMEN', 'MAN', 'MEN')]}, {'section': 'gram9-plural-verbs', 'correct': [], 'incorrect': []}, {'section': 'total', 'correct': [], 'incorrect': [('LONDON', 'ENGLAND', 'PARIS', 'FRANCE'), ('LONDON', 'ENGLAND', 'TOKYO', 'JAPAN'), ('PARIS', 'FRANCE', 'TOKYO', 'JAPAN'), ('PARIS', 'FRANCE', 'LONDON', 'ENGLAND'), ('TOKYO', 'JAPAN', 'LONDON', 'ENGLAND'), ('TOKYO', 'JAPAN', 'PARIS', 'FRANCE'), ('LONDON', 'ENGLAND', 'PARIS', 'FRANCE'), ('PARIS', 'FRANCE', 'TOKYO', 'JAPAN'), ('BOY', 'GIRL', 'HE', 'SHE'), ('BOY', 'GIRL', 'KING', 'QUEEN'), ('BOY', 'GIRL', 'MAN', 'WOMAN'), ('HE', 'SHE', 'KING', 'QUEEN'), ('HE', 'SHE', 'MAN', 'WOMAN'), ('HE', 'SHE', 'BOY', 'GIRL'), ('KING', 'QUEEN', 'MAN', 'WOMAN'), ('KING', 'QUEEN', 'BOY', 'GIRL'), ('KING', 'QUEEN', 'HE', 'SHE'), ('MAN', 'WOMAN', 'BOY', 'GIRL'), ('MAN', 'WOMAN', 'HE', 'SHE'), ('MAN', 'WOMAN', 'KING', 'QUEEN'), ('ENGLAND', 'ENGLISH', 'JAPAN', 'JAPANESE'), ('JAPAN', 'JAPANESE', 'ENGLAND', 'ENGLISH'), ('DREAM', 'DREAMS', 'EYE', 'EYES'), ('DREAM', 'DREAMS', 'MAN', 'MEN'), ('DREAM', 'DREAMS', 'WOMAN', 'WOMEN'), ('EYE', 'EYES', 'MAN', 'MEN'), ('EYE', 'EYES', 'WOMAN', 'WOMEN'), ('EYE', 'EYES', 'DREAM', 'DREAMS'), ('MAN', 'MEN', 'WOMAN', 'WOMEN'), ('MAN', 'MEN', 'DREAM', 'DREAMS'), ('MAN', 'MEN', 'EYE', 'EYES'), ('WOMAN', 'WOMEN', 'DREAM', 'DREAMS'), ('WOMAN', 'WOMEN', 'EYE', 'EYES'), ('WOMAN', 'WOMEN', 'MAN', 'MEN')]}]\n"]}],"source":["#8-7 単語分散表現の評価\n","\n","#内省的評価(人間の判断との相関、アナロジータスク（推論）)\n","#外省的評価（単語分散表現を使って評価）\n","\n","#内省的評価をgensimで行う\n","\n","from gensim.test.utils import datapath\n","print(model.evaluate_word_pairs(datapath('wordsim353.tsv'))) #人間との相関の評価\n","print(model.accuracy(datapath('questions-words.txt'))) #アナロジーの評価"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iXwWb3LLdC9A","outputId":"1c0044bf-9c45-47fa-e74f-f41933271dbc"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: janome in /usr/local/lib/python3.9/dist-packages (0.4.2)\n","Epoch 1/100\n"," 9/50 [====>.........................] - ETA: 50s - loss: 0.6999 - acc: 0.5026"]}],"source":["#9-4 テキスト分類 RNN\n","\n","#from utils import *\n","#utils.py\n","import string\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","\n","#テキストの英語の割合がthresholdよりも多ければ英語とみなす\n","def filter_by_ascii_rate(text, threshold = 0.9):\n","  ascii_letters = set(string.printable)\n","  rate = sum(c in ascii_letters for c in text) / len(text)\n","  return rate <= threshold\n","\n","def load_dataset(filename, n = 5000, state = 6):                                                    \n","  df = pd.read_csv(filename, sep = '\\t')\n","\n","  #Converts multi-class to binary-class\n","  mapping = {1: 0, 2: 0, 4: 1, 5: 1}\n","  df = df[df.star_rating != 3]\n","  df.star_rating = df.star_rating.map(mapping)\n","\n","  #extract Japanese.txt\n","  is_jp = df.review_body.apply(filter_by_ascii_rate)\n","  df = df[is_jp]\n","\n","  #sampling\n","  df = df.sample(frac = 1, random_state = state) #shuffle\n","  grouped = df.groupby('star_rating')\n","  df = grouped.head(n=n)\n","  return df.review_body.values, df.star_rating.values\n","\n","\n","#from preprocessing import *\n","#preprocessing.py\n","import re\n","from bs4 import BeautifulSoup\n","!pip install janome\n","from janome.tokenizer import Tokenizer\n","t = Tokenizer()\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","\n","def build_vocabulary(text, num_words = None):\n","  tokenizer = Tokenizer(num_words = num_words, oov_token = '<UNK>')\n","  tokenizer.fit_on_texts([text])\n","  return tokenizer\n","\n","def clean_html(html, strip = False):\n","  soup = BeautifulSoup(html, 'html.parser')\n","  text = soup.get_text(strip = strip)\n","  return text\n","\n","def tokenize(text):\n","  return t.tokenize(text, wakati = True)\n","\n","def preprocess_dataset(texts):\n","  texts = [clean_html(text) for text in texts]\n","  texts = [' '.join(tokenize(text)) for text in texts]\n","  return texts\n","\n","\n","#models.py\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import Dense, Input, Embedding, SimpleRNN\n","\n","class RNNModel:\n","\n","  def __init__(self, input_dim, output_dim,\n","               emb_dim = 300, hid_dim = 100,\n","               embeddings = None, trainable = True):\n","    self.input = Input(shape = (None,), name = 'input')\n","    if embeddings is None:\n","      self.embedding = Embedding(input_dim = input_dim,\n","                                  output_dim = emb_dim,\n","                                  mask_zero = True,\n","                                  trainable = trainable,\n","                                  name = 'embedding')\n","    else:\n","      self.embedding = Embedding(input_dim = embeddings.shape[0],\n","                                 output_dim = embeddings.shape[1],\n","                                 mazk_zero = True,\n","                                 trainable = trainable,\n","                                 weights = [embeddings],\n","                                 name = 'embedding')\n","    self.rnn = SimpleRNN(hid_dim, name = 'rnn')\n","    self.fc = Dense(output_dim, activation = 'softmax')\n","\n","  def build(self):\n","    x = self.input\n","    embedding = self.embedding(x)\n","    output = self.rnn(embedding)\n","    y = self.fc(output)\n","    return Model(inputs = x, outputs = y)\n","\n","\n","#inference.py\n","import numpy as np\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","\n","class InferenceAPI:\n","\n","  def __init__(self, model, vocab, preprocess):\n","    self.model = model\n","    self.vocab = vocab\n","    self.preprocess = preprocess\n","\n","  def predict_from_texts(self, texts):\n","    x = self.preprocess(texts)\n","    x = self.vocab.texts_to_sequences(x)\n","    return self.predict_from_sequences(x)\n","\n","  def predict_from_sequences(self, sequences):\n","    sequences = pad_sequences(sequences, truncating = 'post')\n","    y = self.model.predict(sequences)\n","    return np.argmax(y, -1)\n","\n","\n","#train.py\n","\n","from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n","from tensorflow.keras.models import load_model\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from sklearn.metrics import f1_score, precision_score, recall_score\n","from sklearn.model_selection import train_test_split\n","\n","#from inference import InferenceAPI\n","#from models import RNNModel\n","#from preprocessing import preprocess_dataset, build_vocabulary\n","#from utils import load_dataset\n","\n","def main():\n","  #ハイパーパラメータの設定\n","  batch_size = 128\n","  epochs = 100\n","  maxlen = 300\n","  model_path = 'models/rnn_model.5h'\n","  num_words = 40000\n","  num_label = 2\n","\n","  #データセットの読み込み\n","  x, y = load_dataset('amazon_reviews_multilingual_JP_v1_00.tsv', n = 5000)\n","\n","  #データセットの前処理\n","  x = preprocess_dataset(x)\n","  x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 42)\n","  vocab = build_vocabulary(x_train, num_words)\n","  x_train = vocab.texts_to_sequences(x_train)\n","  x_test = vocab.texts_to_sequences(x_test)\n","  x_train = pad_sequences(x_train, maxlen = maxlen, truncating = 'post')\n","  x_test = pad_sequences(x_test, maxlen = maxlen, truncating = 'post')\n","\n","  #モデルの構築\n","  model = RNNModel(num_words, num_label, embeddings = None).build()\n","  model.compile(optimizer = 'adam',\n","                loss = 'sparse_categorical_crossentropy',\n","                metrics = ['acc'])\n","  \n","  #コールバックの用意\n","  callbacks = [\n","      EarlyStopping(patience = 3),\n","      ModelCheckpoint(model_path, save_best_only = True)\n","  ]\n","\n","  #モデルの学習\n","  model.fit(x = x_train,\n","            y = y_train,\n","            batch_size = batch_size,\n","            epochs = epochs,\n","            validation_split = 0.2,\n","            callbacks = callbacks,\n","            shuffle = True)\n","  \n","  #予測\n","  model = load_model(model_path)\n","  api = InferenceAPI(model, vocab, preprocess_dataset)\n","  y_pred = api.predict_from_sequences(x_test)\n","  print('precision: {:.4f}'.format(precision_score(y_test, y_pred, average = 'binary')))\n","  print('recall: {:.4f}'.format(recall_score(y_test, y_pred, average = 'binary')))\n","  print('f1: {:.4f}'.format(f1_score(y_test, y_pred, average = 'binary')))\n","\n","main()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":551377,"status":"ok","timestamp":1678631818677,"user":{"displayName":"鈴木慎平","userId":"00141692729728736613"},"user_tz":-540},"id":"8lowWY5FNoLz","outputId":"1d589674-392c-4338-99db-33acdc9516e8"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: janome in /usr/local/lib/python3.8/dist-packages (0.4.2)\n","Epoch 1/100\n","50/50 [==============================] - ETA: 0s - loss: 0.6943 - acc: 0.4892"]},{"name":"stderr","output_type":"stream","text":["WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_3_layer_call_fn, lstm_cell_3_layer_call_and_return_conditional_losses while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"]},{"name":"stdout","output_type":"stream","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 75s 1s/step - loss: 0.6943 - acc: 0.4892 - val_loss: 0.6936 - val_acc: 0.5019\n","Epoch 2/100\n","50/50 [==============================] - ETA: 0s - loss: 0.6940 - acc: 0.4812"]},{"name":"stderr","output_type":"stream","text":["WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_3_layer_call_fn, lstm_cell_3_layer_call_and_return_conditional_losses while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"]},{"name":"stdout","output_type":"stream","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 67s 1s/step - loss: 0.6940 - acc: 0.4812 - val_loss: 0.6931 - val_acc: 0.5019\n","Epoch 3/100\n","50/50 [==============================] - 57s 1s/step - loss: 0.6934 - acc: 0.5034 - val_loss: 0.6937 - val_acc: 0.4981\n","Epoch 4/100\n","50/50 [==============================] - 58s 1s/step - loss: 0.6936 - acc: 0.4906 - val_loss: 0.6933 - val_acc: 0.4981\n","Epoch 5/100\n","50/50 [==============================] - 58s 1s/step - loss: 0.6934 - acc: 0.5025 - val_loss: 0.6934 - val_acc: 0.5019\n","63/63 [==============================] - 8s 119ms/step\n","precision: 0.5045\n","recall: 1.0000\n","f1: 0.6707\n"]}],"source":["#9-6 LSTM(Long Short Term Memory)\n","\n","#from utils import *\n","#utils.py\n","import string\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","\n","#テキストの英語の割合がthresholdよりも多ければ英語とみなす\n","def filter_by_ascii_rate(text, threshold = 0.9):\n","  ascii_letters = set(string.printable)\n","  rate = sum(c in ascii_letters for c in text) / len(text)\n","  return rate <= threshold\n","\n","def load_dataset(filename, n = 5000, state = 6):                                                    \n","  df = pd.read_csv(filename, sep = '\\t')\n","\n","  #Converts multi-class to binary-class\n","  mapping = {1: 0, 2: 0, 4: 1, 5: 1}\n","  df = df[df.star_rating != 3]\n","  df.star_rating = df.star_rating.map(mapping)\n","\n","  #extract Japanese.txt\n","  is_jp = df.review_body.apply(filter_by_ascii_rate)\n","  df = df[is_jp]\n","\n","  #sampling\n","  df = df.sample(frac = 1, random_state = state) #shuffle\n","  grouped = df.groupby('star_rating')\n","  df = grouped.head(n=n)\n","  return df.review_body.values, df.star_rating.values\n","\n","\n","#from preprocessing import *\n","#preprocessing.py\n","import re\n","from bs4 import BeautifulSoup\n","!pip install janome\n","from janome.tokenizer import Tokenizer\n","t = Tokenizer()\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","\n","def build_vocabulary(text, num_words = None):\n","  tokenizer = Tokenizer(num_words = num_words, oov_token = '<UNK>')\n","  tokenizer.fit_on_texts([text])\n","  return tokenizer\n","\n","def clean_html(html, strip = False):\n","  soup = BeautifulSoup(html, 'html.parser')\n","  text = soup.get_text(strip = strip)\n","  return text\n","\n","def tokenize(text):\n","  return t.tokenize(text, wakati = True)\n","\n","def preprocess_dataset(texts):\n","  texts = [clean_html(text) for text in texts]\n","  texts = [' '.join(tokenize(text)) for text in texts]\n","  return texts\n","\n","\n","#models.py\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import Dense, Input, Embedding, LSTM\n","\n","class LSTMModel:\n","\n","  def __init__(self, input_dim, output_dim,\n","               emb_dim = 300, hid_dim = 100,\n","               embeddings = None, trainable = True):\n","    self.input = Input(shape = (None,), name = 'input')\n","    if embeddings is None:\n","      self.embedding = Embedding(input_dim = input_dim,\n","                                  output_dim = emb_dim,\n","                                  mask_zero = True,\n","                                  trainable = trainable,\n","                                  name = 'embedding')\n","    else:\n","      self.embedding = Embedding(input_dim = embeddings.shape[0],\n","                                 output_dim = embeddings.shape[1],\n","                                 mazk_zero = True,\n","                                 trainable = trainable,\n","                                 weights = [embeddings],\n","                                 name = 'embedding')\n","    self.lstm = LSTM(hid_dim, name = 'lstm')\n","    self.fc = Dense(output_dim, activation = 'softmax')\n","\n","  def build(self):\n","    x = self.input\n","    embedding = self.embedding(x)\n","    output = self.lstm(embedding)\n","    y = self.fc(output)\n","    return Model(inputs = x, outputs = y)\n","\n","\n","#inference.py\n","import numpy as np\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","\n","class InferenceAPI:\n","\n","  def __init__(self, model, vocab, preprocess):\n","    self.model = model\n","    self.vocab = vocab\n","    self.preprocess = preprocess\n","\n","  def predict_from_texts(self, texts):\n","    x = self.preprocess(texts)\n","    x = self.vocab.texts_to_sequences(x)\n","    return self.predict_from_sequences(x)\n","\n","  def predict_from_sequences(self, sequences):\n","    sequences = pad_sequences(sequences, truncating = 'post')\n","    y = self.model.predict(sequences)\n","    return np.argmax(y, -1)\n","\n","\n","#train.py\n","\n","from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n","from tensorflow.keras.models import load_model\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from sklearn.metrics import f1_score, precision_score, recall_score\n","from sklearn.model_selection import train_test_split\n","\n","#from inference import InferenceAPI\n","#from models import LSTMModel\n","#from preprocessing import preprocess_dataset, build_vocabulary\n","#from utils import load_dataset\n","\n","def main():\n","  #ハイパーパラメータの設定\n","  batch_size = 128\n","  epochs = 100\n","  maxlen = 300\n","  model_path = 'models/lstm_model.5h'\n","  num_words = 40000\n","  num_label = 2\n","\n","  #データセットの読み込み\n","  x, y = load_dataset('amazon_reviews_multilingual_JP_v1_00.tsv', n = 5000)\n","\n","  #データセットの前処理\n","  x = preprocess_dataset(x)\n","  x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 42)\n","  vocab = build_vocabulary(x_train, num_words)\n","  x_train = vocab.texts_to_sequences(x_train)\n","  x_test = vocab.texts_to_sequences(x_test)\n","  x_train = pad_sequences(x_train, maxlen = maxlen, truncating = 'post')\n","  x_test = pad_sequences(x_test, maxlen = maxlen, truncating = 'post')\n","\n","  #モデルの構築\n","  model = LSTMModel(num_words, num_label, embeddings = None).build()\n","  model.compile(optimizer = 'adam',\n","                loss = 'sparse_categorical_crossentropy',\n","                metrics = ['acc'])\n","  \n","  #コールバックの用意\n","  callbacks = [\n","      EarlyStopping(patience = 3),\n","      ModelCheckpoint(model_path, save_best_only = True)\n","  ]\n","\n","  #モデルの学習\n","  model.fit(x = x_train,\n","            y = y_train,\n","            batch_size = batch_size,\n","            epochs = epochs,\n","            validation_split = 0.2,\n","            callbacks = callbacks,\n","            shuffle = True)\n","  \n","  #予測\n","  model = load_model(model_path)\n","  api = InferenceAPI(model, vocab, preprocess_dataset)\n","  y_pred = api.predict_from_sequences(x_test)\n","  print('precision: {:.4f}'.format(precision_score(y_test, y_pred, average = 'binary')))\n","  print('recall: {:.4f}'.format(recall_score(y_test, y_pred, average = 'binary')))\n","  print('f1: {:.4f}'.format(f1_score(y_test, y_pred, average = 'binary')))\n","\n","main()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kLaLm3j2_jIQ","executionInfo":{"status":"ok","timestamp":1678677289002,"user_tz":-540,"elapsed":98191,"user":{"displayName":"鈴木慎平","userId":"00141692729728736613"}},"outputId":"a9db21dc-e4aa-45f7-816b-dcc07a225de5"},"outputs":[{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: janome in /usr/local/lib/python3.9/dist-packages (0.4.2)\n","Epoch 1/100\n","50/50 [==============================] - ETA: 0s - loss: 0.6952 - acc: 0.5033"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _update_step_xla while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["50/50 [==============================] - 99s 2s/step - loss: 0.6952 - acc: 0.5033 - val_loss: 0.6936 - val_acc: 0.5163\n","Epoch 2/100\n","50/50 [==============================] - ETA: 0s - loss: 0.6925 - acc: 0.5244"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _update_step_xla while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"]},{"output_type":"stream","name":"stdout","text":["50/50 [==============================] - 99s 2s/step - loss: 0.6925 - acc: 0.5244 - val_loss: 0.6914 - val_acc: 0.5163\n","Epoch 3/100\n","50/50 [==============================] - 89s 2s/step - loss: 0.6933 - acc: 0.5133 - val_loss: 0.6918 - val_acc: 0.5163\n","Epoch 4/100\n","50/50 [==============================] - 95s 2s/step - loss: 0.6926 - acc: 0.5044 - val_loss: 0.6918 - val_acc: 0.5163\n","Epoch 5/100\n","50/50 [==============================] - 89s 2s/step - loss: 0.6918 - acc: 0.5105 - val_loss: 0.6918 - val_acc: 0.5019\n","63/63 [==============================] - 5s 84ms/step\n","precision: 0.5155\n","recall: 0.0991\n","f1: 0.1663\n"]}],"source":["#9-8 CNN\n","\n","#from utils import *\n","#utils.py\n","import string\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","\n","#テキストの英語の割合がthresholdよりも多ければ英語とみなす\n","def filter_by_ascii_rate(text, threshold = 0.9):\n","  ascii_letters = set(string.printable)\n","  rate = sum(c in ascii_letters for c in text) / len(text)\n","  return rate <= threshold\n","\n","def load_dataset(filename, n = 5000, state = 6):                                                    \n","  df = pd.read_csv(filename, sep = '\\t')\n","\n","  #Converts multi-class to binary-class\n","  mapping = {1: 0, 2: 0, 4: 1, 5: 1}\n","  df = df[df.star_rating != 3]\n","  df.star_rating = df.star_rating.map(mapping)\n","\n","  #extract Japanese.txt\n","  is_jp = df.review_body.apply(filter_by_ascii_rate)\n","  df = df[is_jp]\n","\n","  #sampling\n","  df = df.sample(frac = 1, random_state = state) #shuffle\n","  grouped = df.groupby('star_rating')\n","  df = grouped.head(n=n)\n","  return df.review_body.values, df.star_rating.values\n","\n","\n","#from preprocessing import *\n","#preprocessing.py\n","import re\n","from bs4 import BeautifulSoup\n","!pip install janome\n","from janome.tokenizer import Tokenizer\n","t = Tokenizer()\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","\n","def build_vocabulary(text, num_words = None):\n","  tokenizer = Tokenizer(num_words = num_words, oov_token = '<UNK>')\n","  tokenizer.fit_on_texts([text])\n","  return tokenizer\n","\n","def clean_html(html, strip = False):\n","  soup = BeautifulSoup(html, 'html.parser')\n","  text = soup.get_text(strip = strip)\n","  return text\n","\n","def tokenize(text):\n","  return t.tokenize(text, wakati = True)\n","\n","def preprocess_dataset(texts):\n","  texts = [clean_html(text) for text in texts]\n","  texts = [' '.join(tokenize(text)) for text in texts]\n","  return texts\n","\n","\n","#models.py\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import Dense, Input, Embedding, Conv1D, GlobalMaxPooling1D\n","\n","class CNNModel:\n","\n","  def __init__(self, input_dim, output_dim, filters = 250, kernel_size = 3, emb_dim = 300, embeddings = None, trainable = True):\n","    self.input = Input(shape = (None,), name = 'input')\n","    if embeddings is None:\n","      self.embedding = Embedding(input_dim = input_dim,\n","                                  output_dim = emb_dim,\n","                                  trainable = trainable,\n","                                  name = 'embedding')\n","    else:\n","      self.embedding = Embedding(input_dim = embeddings.shape[0],\n","                                 output_dim = embeddings.shape[1],\n","                                 trainable = trainable,\n","                                 weights = [embeddings],\n","                                 name = 'embedding')\n","    self.conv = Conv1D(filters, kernel_size, padding = 'valid', activation = 'relu', strides = 1)\n","    self.pool = GlobalMaxPooling1D()\n","    self.fc = Dense(output_dim, activation = 'softmax')\n","\n","  def build(self):\n","    x = self.input\n","    embedding = self.embedding(x)\n","    conv = self.conv(embedding)\n","    pool = self.pool(conv)\n","    y = self.fc(pool)\n","    return Model(inputs = x, outputs = y)\n","\n","\n","#inference.py\n","import numpy as np\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","\n","class InferenceAPI:\n","\n","  def __init__(self, model, vocab, preprocess):\n","    self.model = model\n","    self.vocab = vocab\n","    self.preprocess = preprocess\n","\n","  def predict_from_texts(self, texts):\n","    x = self.preprocess(texts)\n","    x = self.vocab.texts_to_sequences(x)\n","    return self.predict_from_sequences(x)\n","\n","  def predict_from_sequences(self, sequences):\n","    sequences = pad_sequences(sequences, truncating = 'post')\n","    y = self.model.predict(sequences)\n","    return np.argmax(y, -1)\n","\n","\n","#train.py\n","\n","from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n","from tensorflow.keras.models import load_model\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from sklearn.metrics import f1_score, precision_score, recall_score\n","from sklearn.model_selection import train_test_split\n","\n","#from inference import InferenceAPI\n","#from models import CNNModel\n","#from preprocessing import preprocess_dataset, build_vocabulary\n","#from utils import load_dataset\n","\n","def main():\n","  #ハイパーパラメータの設定\n","  batch_size = 128\n","  epochs = 100\n","  maxlen = 300\n","  model_path = 'models/cnn_model.5h'\n","  num_words = 40000\n","  num_label = 2\n","\n","  #データセットの読み込み\n","  x, y = load_dataset('amazon_reviews_multilingual_JP_v1_00.tsv', n = 5000)\n","\n","  #データセットの前処理\n","  x = preprocess_dataset(x)\n","  x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 42)\n","  vocab = build_vocabulary(x_train, num_words)\n","  x_train = vocab.texts_to_sequences(x_train)\n","  x_test = vocab.texts_to_sequences(x_test)\n","  x_train = pad_sequences(x_train, maxlen = maxlen, truncating = 'post')\n","  x_test = pad_sequences(x_test, maxlen = maxlen, truncating = 'post')\n","\n","  #モデルの構築\n","  model = CNNModel(num_words, num_label, embeddings = None).build()\n","  model.compile(optimizer = 'adam',\n","                loss = 'sparse_categorical_crossentropy',\n","                metrics = ['acc'])\n","  \n","  #コールバックの用意\n","  callbacks = [\n","      EarlyStopping(patience = 3),\n","      ModelCheckpoint(model_path, save_best_only = True)\n","  ]\n","\n","  #モデルの学習\n","  model.fit(x = x_train,\n","            y = y_train,\n","            batch_size = batch_size,\n","            epochs = epochs,\n","            validation_split = 0.2,\n","            callbacks = callbacks,\n","            shuffle = True)\n","  \n","  #予測\n","  model = load_model(model_path)\n","  api = InferenceAPI(model, vocab, preprocess_dataset)\n","  y_pred = api.predict_from_sequences(x_test)\n","  print('precision: {:.4f}'.format(precision_score(y_test, y_pred, average = 'binary')))\n","  print('recall: {:.4f}'.format(recall_score(y_test, y_pred, average = 'binary')))\n","  print('f1: {:.4f}'.format(f1_score(y_test, y_pred, average = 'binary')))\n","\n","main()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Yy0cqZ0ez5Le","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1678681094611,"user_tz":-540,"elapsed":367105,"user":{"displayName":"鈴木慎平","userId":"00141692729728736613"}},"outputId":"053a0ec4-9750-4619-86ed-48b6d0b3f03f"},"outputs":[{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: janome in /usr/local/lib/python3.9/dist-packages (0.4.2)\n","Epoch 1/100\n","50/50 [==============================] - ETA: 0s - loss: 0.6932 - acc: 0.4981"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _update_step_xla while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"]},{"output_type":"stream","name":"stdout","text":["50/50 [==============================] - 95s 2s/step - loss: 0.6932 - acc: 0.4981 - val_loss: 0.6932 - val_acc: 0.4981\n","Epoch 2/100\n","50/50 [==============================] - ETA: 0s - loss: 0.6932 - acc: 0.4941"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _update_step_xla while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 89s 2s/step - loss: 0.6932 - acc: 0.4941 - val_loss: 0.6932 - val_acc: 0.4981\n","Epoch 3/100\n","50/50 [==============================] - 99s 2s/step - loss: 0.6932 - acc: 0.5019 - val_loss: 0.6932 - val_acc: 0.4981\n","Epoch 4/100\n","50/50 [==============================] - 90s 2s/step - loss: 0.6932 - acc: 0.5019 - val_loss: 0.6932 - val_acc: 0.4981\n","Epoch 5/100\n","50/50 [==============================] - 90s 2s/step - loss: 0.6932 - acc: 0.5019 - val_loss: 0.6932 - val_acc: 0.4981\n","63/63 [==============================] - 5s 84ms/step\n","precision: 0.0000\n","recall: 0.0000\n","f1: 0.0000\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]}],"source":["#9-9 学習済み単語分散表現の使用\n","\n","#from utils import *\n","#utils.py\n","import gensim\n","import numpy as np\n","\n","def filter_embeddings(embeddings, vocab, num_words, dim = 300):\n","  _embeddings = np.zeros((num_words, dim))\n","  for word in vocab:\n","    if word in embeddings:\n","      word_id = vocab[word]\n","      if word_id >= num_words:\n","        continue\n","      _embeddings[word_id] = embeddings[word]\n","  return _embeddings\n","\n","def load_fasttext(filepath, binary = False):\n","  model = gensim.models.KeyedVectors.load_word2vec_format(filepath, binary = binary)\n","  return model\n","\n","\n","#from preprocessing import *\n","#preprocessing.py\n","import re\n","from bs4 import BeautifulSoup\n","!pip install janome\n","from janome.tokenizer import Tokenizer\n","t = Tokenizer()\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","\n","def build_vocabulary(text, num_words = None):\n","  tokenizer = Tokenizer(num_words = num_words, oov_token = '<UNK>')\n","  tokenizer.fit_on_texts([text])\n","  return tokenizer\n","\n","def clean_html(html, strip = False):\n","  soup = BeautifulSoup(html, 'html.parser')\n","  text = soup.get_text(strip = strip)\n","  return text\n","\n","def tokenize(text):\n","  return t.tokenize(text, wakati = True)\n","\n","def preprocess_dataset(texts):\n","  texts = [clean_html(text) for text in texts]\n","  texts = [' '.join(tokenize(text)) for text in texts]\n","  return texts\n","\n","\n","#models.py\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import Dense, Input, Embedding, Conv1D, GlobalMaxPooling1D\n","\n","class CNNModel:\n","\n","  def __init__(self, input_dim, output_dim, filters = 250, kernel_size = 3, emb_dim = 300, embeddings = None, trainable = True):\n","    self.input = Input(shape = (None,), name = 'input')\n","    if embeddings is None:\n","      self.embedding = Embedding(input_dim = input_dim,\n","                                  output_dim = emb_dim,\n","                                  trainable = trainable,\n","                                  name = 'embedding')\n","    else:\n","      self.embedding = Embedding(input_dim = embeddings.shape[0],\n","                                 output_dim = embeddings.shape[1],\n","                                 trainable = trainable,\n","                                 weights = [embeddings],\n","                                 name = 'embedding')\n","    self.conv = Conv1D(filters, kernel_size, padding = 'valid', activation = 'relu', strides = 1)\n","    self.pool = GlobalMaxPooling1D()\n","    self.fc = Dense(output_dim, activation = 'softmax')\n","\n","  def build(self):\n","    x = self.input\n","    embedding = self.embedding(x)\n","    conv = self.conv(embedding)\n","    pool = self.pool(conv)\n","    y = self.fc(pool)\n","    return Model(inputs = x, outputs = y)\n","\n","\n","#inference.py\n","import numpy as np\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","\n","class InferenceAPI:\n","\n","  def __init__(self, model, vocab, preprocess):\n","    self.model = model\n","    self.vocab = vocab\n","    self.preprocess = preprocess\n","\n","  def predict_from_texts(self, texts):\n","    x = self.preprocess(texts)\n","    x = self.vocab.texts_to_sequences(x)\n","    return self.predict_from_sequences(x)\n","\n","  def predict_from_sequences(self, sequences):\n","    sequences = pad_sequences(sequences, truncating = 'post')\n","    y = self.model.predict(sequences)\n","    return np.argmax(y, -1)\n","\n","\n","#train.py\n","\n","from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n","from tensorflow.keras.models import load_model\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from sklearn.metrics import f1_score, precision_score, recall_score\n","from sklearn.model_selection import train_test_split\n","\n","#from inference import InferenceAPI\n","#from models import CNNModel\n","#from preprocessing import preprocess_dataset, build_vocabulary\n","#from utils import load_dataset\n","\n","def main():\n","  #ハイパーパラメータの設定\n","  batch_size = 128\n","  epochs = 100\n","  maxlen = 300\n","  model_path = 'models/model.5h'\n","  num_words = 40000\n","  num_label = 2\n","\n","  #データセットの読み込み\n","  x, y = load_dataset('amazon_reviews_multilingual_JP_v1_00.tsv', n = 5000)\n","\n","  #データセットの前処理\n","  x = preprocess_dataset(x)\n","  x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 42)\n","  vocab = build_vocabulary(x_train, num_words)\n","  x_train = vocab.texts_to_sequences(x_train)\n","  x_test = vocab.texts_to_sequences(x_test)\n","  x_train = pad_sequences(x_train, maxlen = maxlen, truncating = 'post')\n","  x_test = pad_sequences(x_test, maxlen = maxlen, truncating = 'post')\n","\n","  #単語分散表現の用意\n","  wv = load_fasttext('cc.ja.300.vec.gz')\n","  wv = filter_embeddings(wv, vocab.word_index, num_words)\n","\n","  #モデルの構築\n","  model = CNNModel(num_words, num_label, embeddings = wv).build()\n","  model.compile(optimizer = 'adam',\n","                loss = 'sparse_categorical_crossentropy',\n","                metrics = ['acc'])\n","  \n","  #コールバックの用意\n","  callbacks = [\n","      EarlyStopping(patience = 3),\n","      ModelCheckpoint(model_path, save_best_only = True)\n","  ]\n","\n","  #モデルの学習\n","  model.fit(x = x_train, y = y_train, batch_size = batch_size, epochs = epochs, validation_split = 0.2, callbacks = callbacks, shuffle = True)\n","  \n","  #予測\n","  model = load_model(model_path)\n","  api = InferenceAPI(model, vocab, preprocess_dataset)\n","  y_pred = api.predict_from_sequences(x_test)\n","  print('precision: {:.4f}'.format(precision_score(y_test, y_pred, average = 'binary')))\n","  print('recall: {:.4f}'.format(recall_score(y_test, y_pred, average = 'binary')))\n","  print('f1: {:.4f}'.format(f1_score(y_test, y_pred, average = 'binary')))\n","\n","main()"]},{"cell_type":"code","source":["#10-4 系列ラベリング LSTMによる固有表現認識器の実装\n","\n","#utils.py\n","def load_dataset(filename, encoding = 'utf-8'):\n","  sents, labels = [], []\n","  words, tags = [], []\n","  with open(filename, encoding = encoding) as f:\n","    for line in f:\n","      line = line.rstrip()\n","      if line:\n","        word, tag = line.split('\\t')\n","        words.append(word)\n","        tags.append(tag)\n","      else:\n","        sents.append(words)\n","        labels.append(tags)\n","        words, tags = [], []\n","    if words:\n","      sents.append(words)\n","      labels.append(tags)\n","\n","  return sents, labels\n","\n","\n","#preprocessing.py\n","\n","import re\n","\n","import tensorflow as tf\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","\n","class Vocab:\n","\n","  def __init__(self, num_words = None, lower = True, oov_token = None):\n","    self.tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words = num_words, oov_token = oov_token, filters = '', lower = lower, split = '\\t')\n","\n","  def fit(self, sequences):\n","    texts = self._texts(sequences)\n","    self.tokenizer.fit_on_texts(texts)\n","    return self\n","\n","  def encode(self, sequences):\n","    texts = self._texts(sequences)\n","    return self.tokenizer.texts_to_sequences(texts)\n","\n","  def decode(self, sequences):\n","    texts = self.tokenizer.sequences_to_texts(sequences)\n","    return [text.split(' ') for text in texts]\n","\n","  def _texts(self, sequences):\n","    return ['\\t'.join(words) for words in sequences]\n","\n","  def get_index(self, word):\n","    return self.tokenizer.word_index.get(word)\n","\n","  @property\n","  def size(self):\n","    return len(self.tokenizer.word_index) + 1\n","\n","  def save(self, file_path):\n","    with open(file_path, 'w') as f:\n","      config = self.tokenizer.to_json()\n","      f.write(config)\n","\n","  @classmethod\n","  def load(cls, file_path):\n","    with open(file_path) as f:\n","      tokenizer = tf.keras.preprocessing.text.tokenizer_from_json(f_read())\n","      vocab = cls()\n","      vocab.tokenizer = tokenizer\n","    return vocab\n","\n","\n","def normalize_number(text, reduce = True):\n","  if reduce:\n","    normalized_text = re.sub(r'\\d+', '0', text)\n","  else:\n","    normalized_text = re.sub(r'\\d', '0', text)\n","  return normalized_text\n","\n","def preprocess_dataset(sequences):\n","  sequences = [[normalize_number(w) for w in words] for words in sequences]\n","  return sequences\n","\n","def create_dataset(sequences, vocab):\n","  sequences = vocab.encode(sequences)\n","  sequences = pad_sequences(sequences, padding = 'post')\n","  return sequences\n","\n","\n","#models.py\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import Dense, Input, Embedding, LSTM\n","\n","class UnidirectionalModel:\n","\n","  def __init__(self, input_dim, output_dim, emb_dim = 100, hid_dim = 100):\n","    self.input = Input(shape = (None,), name = 'input')\n","    self.embedding = Embedding(input_dim = input_dim, output_dim = emb_dim, mask_zero = True, name = 'embedding')\n","    self.lstm = LSTM(hid_dim, return_sequences = True, name = 'lstm')\n","    self.fc = Dense(output_dim, activation = 'softmax')\n","\n","  def build(self):\n","    x = self.input\n","    embedding = self.embedding(x)\n","    lstm = self.lstm(embedding)\n","    y = self.fc(lstm)\n","    return Model(inputs = x, outputs = y)\n","\n","\n","#inference.py\n","import numpy as np\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","\n","class InferenceAPI:\n","\n","  def __init__(self, model, source_vocab, target_vocab):\n","    self.model = model\n","    self.source_vocab = source_vocab\n","    self.target_vocab = target_vocab\n","\n","  def predict_from_sequences(self, sequences):\n","    lengths = map(len, sequences)\n","    sequences = self.source_vocab.encode(sequences)\n","    sequences = pad_sequences(sequences, padding = 'post')\n","    y_pred = self.model.predict(sequences)\n","    y_pred = np.argmax(y_pred, axis = -1)\n","    y_pred = self.target_vocab.decode(y_pred)\n","    y_pred = [y[:l] for y ,l in zip(y_pred, lengths)]\n","    return y_pred\n","\n","\n","#系列ラベルの評価用パッケージであるseqevalのインストール\n","!pip install seqeval\n","\n","\n","#train.py\n","from sklearn.model_selection import train_test_split\n","from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n","from tensorflow.keras.models import load_model\n","from seqeval.metrics import classification_report\n","\n","#from inference import InferenceAPI\n","#from models import UnidirectionalModel\n","#from preprocessing import create_dataset, preprocess_dataset, Vocab\n","#from utils import load_dataset\n","\n","def main():\n","  #ハイパーパラメータの設定\n","  batch_size = 32\n","  epochs = 100\n","  model_path = 'models/undirectional_model.5h'\n","  num_words = 15000\n","\n","  #データセットの読み込み\n","  x, y = load_dataset('ja.wikipedia.conll')\n","\n","  #データセットの前処理\n","  x = preprocess_dataset(x)\n","  x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 42)\n","  source_vocab = Vocab(num_words  = num_words, oov_token = '<UNK>').fit(x_train)\n","  target_vocab = Vocab(lower = False).fit(y_train)\n","  x_train = create_dataset(x_train, source_vocab)\n","  y_train = create_dataset(y_train, target_vocab)\n","\n","  #モデルの構築\n","  model = UnidirectionalModel(num_words, target_vocab.size).build()\n","  model.compile(optimizer = 'adam',\n","                loss = 'sparse_categorical_crossentropy')\n","  \n","  #コールバックの用意\n","  callbacks = [\n","      EarlyStopping(patience = 3),\n","      ModelCheckpoint(model_path, save_best_only = True)\n","  ]\n","\n","  #モデルの学習\n","  model.fit(x = x_train, y = y_train, batch_size = batch_size, epochs = epochs, validation_split = 0.2, callbacks = callbacks, shuffle = True)\n","  \n","  #予測\n","  model = load_model(model_path)\n","  api = InferenceAPI(model, source_vocab, target_vocab)\n","  y_pred = api.predict_from_sequences(x_test)\n","  print(classification_report(y_test, y_pred, digits = 4))\n","\n","main()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"E4i59LIJ5YK0","executionInfo":{"status":"ok","timestamp":1678720221281,"user_tz":-540,"elapsed":340348,"user":{"displayName":"鈴木慎平","userId":"00141692729728736613"}},"outputId":"6bc4eb7e-c594-494d-c765-788e9651030f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: seqeval in /usr/local/lib/python3.9/dist-packages (1.2.2)\n","Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.9/dist-packages (from seqeval) (1.22.4)\n","Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.9/dist-packages (from seqeval) (1.2.1)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.2.0)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn>=0.21.3->seqeval) (3.1.0)\n","Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.9/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.10.1)\n","Epoch 1/100\n","20/20 [==============================] - ETA: 0s - loss: 2.1254"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r20/20 [==============================] - 17s 688ms/step - loss: 2.1254 - val_loss: 1.0271\n","Epoch 2/100\n","20/20 [==============================] - ETA: 0s - loss: 0.8934"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r20/20 [==============================] - 12s 648ms/step - loss: 0.8934 - val_loss: 0.8717\n","Epoch 3/100\n","20/20 [==============================] - ETA: 0s - loss: 0.8305"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r20/20 [==============================] - 12s 649ms/step - loss: 0.8305 - val_loss: 0.8414\n","Epoch 4/100\n","20/20 [==============================] - ETA: 0s - loss: 0.8032"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r20/20 [==============================] - 12s 647ms/step - loss: 0.8032 - val_loss: 0.8112\n","Epoch 5/100\n","20/20 [==============================] - ETA: 0s - loss: 0.7631"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r20/20 [==============================] - 12s 639ms/step - loss: 0.7631 - val_loss: 0.7640\n","Epoch 6/100\n","20/20 [==============================] - ETA: 0s - loss: 0.6991"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r20/20 [==============================] - 13s 694ms/step - loss: 0.6991 - val_loss: 0.6991\n","Epoch 7/100\n","20/20 [==============================] - ETA: 0s - loss: 0.6193"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r20/20 [==============================] - 13s 654ms/step - loss: 0.6193 - val_loss: 0.6341\n","Epoch 8/100\n","20/20 [==============================] - ETA: 0s - loss: 0.5488"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r20/20 [==============================] - 13s 678ms/step - loss: 0.5488 - val_loss: 0.5896\n","Epoch 9/100\n","20/20 [==============================] - ETA: 0s - loss: 0.4974"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r20/20 [==============================] - 15s 751ms/step - loss: 0.4974 - val_loss: 0.5596\n","Epoch 10/100\n","20/20 [==============================] - ETA: 0s - loss: 0.4599"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r20/20 [==============================] - 13s 696ms/step - loss: 0.4599 - val_loss: 0.5362\n","Epoch 11/100\n","20/20 [==============================] - ETA: 0s - loss: 0.4285"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r20/20 [==============================] - 13s 699ms/step - loss: 0.4285 - val_loss: 0.5189\n","Epoch 12/100\n","20/20 [==============================] - ETA: 0s - loss: 0.3998"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r20/20 [==============================] - 14s 738ms/step - loss: 0.3998 - val_loss: 0.4995\n","Epoch 13/100\n","20/20 [==============================] - ETA: 0s - loss: 0.3730"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r20/20 [==============================] - 13s 690ms/step - loss: 0.3730 - val_loss: 0.4816\n","Epoch 14/100\n","20/20 [==============================] - ETA: 0s - loss: 0.3479"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r20/20 [==============================] - 14s 752ms/step - loss: 0.3479 - val_loss: 0.4673\n","Epoch 15/100\n","20/20 [==============================] - ETA: 0s - loss: 0.3282"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r20/20 [==============================] - 13s 691ms/step - loss: 0.3282 - val_loss: 0.4600\n","Epoch 16/100\n","20/20 [==============================] - ETA: 0s - loss: 0.3105"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r20/20 [==============================] - 14s 713ms/step - loss: 0.3105 - val_loss: 0.4556\n","Epoch 17/100\n","20/20 [==============================] - ETA: 0s - loss: 0.2972"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r20/20 [==============================] - 14s 706ms/step - loss: 0.2972 - val_loss: 0.4471\n","Epoch 18/100\n","20/20 [==============================] - 4s 198ms/step - loss: 0.2853 - val_loss: 0.4541\n","Epoch 19/100\n","20/20 [==============================] - ETA: 0s - loss: 0.2738"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r20/20 [==============================] - 16s 837ms/step - loss: 0.2738 - val_loss: 0.4415\n","Epoch 20/100\n","20/20 [==============================] - ETA: 0s - loss: 0.2641"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r20/20 [==============================] - 14s 715ms/step - loss: 0.2641 - val_loss: 0.4383\n","Epoch 21/100\n","20/20 [==============================] - 4s 189ms/step - loss: 0.2539 - val_loss: 0.4507\n","Epoch 22/100\n","20/20 [==============================] - ETA: 0s - loss: 0.2438"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r20/20 [==============================] - 14s 719ms/step - loss: 0.2438 - val_loss: 0.4362\n","Epoch 23/100\n","20/20 [==============================] - 4s 185ms/step - loss: 0.2324 - val_loss: 0.4403\n","Epoch 24/100\n","20/20 [==============================] - 5s 240ms/step - loss: 0.2215 - val_loss: 0.4375\n","Epoch 25/100\n","20/20 [==============================] - 4s 192ms/step - loss: 0.2108 - val_loss: 0.4442\n","7/7 [==============================] - 2s 46ms/step\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","    ARTIFACT     0.0092    0.0065    0.0076       154\n","        DATE     0.4183    0.8127    0.5523       315\n","       EVENT     0.0000    0.0000    0.0000        64\n","    LOCATION     0.5019    0.4962    0.4990       526\n","       MONEY     0.0000    0.0000    0.0000        12\n","      NUMBER     0.0772    0.1101    0.0907       218\n","ORGANIZATION     0.0932    0.1048    0.0987       248\n","       OTHER     0.0000    0.0000    0.0000        75\n","     PERCENT     0.0000    0.0000    0.0000        52\n","      PERSON     0.0787    0.0312    0.0447       224\n","        TIME     0.0000    0.0000    0.0000         5\n","\n","   micro avg     0.2993    0.3038    0.3015      1893\n","   macro avg     0.1071    0.1420    0.1176      1893\n","weighted avg     0.2402    0.3038    0.2599      1893\n","\n"]}]},{"cell_type":"code","source":["#10-6 双方向LSTM\n","\n","#10-4 系列ラベリング LSTMによる固有表現認識器の実装\n","\n","#utils.py\n","def load_dataset(filename, encoding = 'utf-8'):\n","  sents, labels = [], []\n","  words, tags = [], []\n","  with open(filename, encoding = encoding) as f:\n","    for line in f:\n","      line = line.rstrip()\n","      if line:\n","        word, tag = line.split('\\t')\n","        words.append(word)\n","        tags.append(tag)\n","      else:\n","        sents.append(words)\n","        labels.append(tags)\n","        words, tags = [], []\n","    if words:\n","      sents.append(words)\n","      labels.append(tags)\n","\n","  return sents, labels\n","\n","\n","#preprocessing.py\n","\n","import re\n","\n","import tensorflow as tf\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","\n","class Vocab:\n","\n","  def __init__(self, num_words = None, lower = True, oov_token = None):\n","    self.tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words = num_words, oov_token = oov_token, filters = '', lower = lower, split = '\\t')\n","\n","  def fit(self, sequences):\n","    texts = self._texts(sequences)\n","    self.tokenizer.fit_on_texts(texts)\n","    return self\n","\n","  def encode(self, sequences):\n","    texts = self._texts(sequences)\n","    return self.tokenizer.texts_to_sequences(texts)\n","\n","  def decode(self, sequences):\n","    texts = self.tokenizer.sequences_to_texts(sequences)\n","    return [text.split(' ') for text in texts]\n","\n","  def _texts(self, sequences):\n","    return ['\\t'.join(words) for words in sequences]\n","\n","  def get_index(self, word):\n","    return self.tokenizer.word_index.get(word)\n","\n","  @property\n","  def size(self):\n","    return len(self.tokenizer.word_index) + 1\n","\n","  def save(self, file_path):\n","    with open(file_path, 'w') as f:\n","      config = self.tokenizer.to_json()\n","      f.write(config)\n","\n","  @classmethod\n","  def load(cls, file_path):\n","    with open(file_path) as f:\n","      tokenizer = tf.keras.preprocessing.text.tokenizer_from_json(f_read())\n","      vocab = cls()\n","      vocab.tokenizer = tokenizer\n","    return vocab\n","\n","\n","def normalize_number(text, reduce = True):\n","  if reduce:\n","    normalized_text = re.sub(r'\\d+', '0', text)\n","  else:\n","    normalized_text = re.sub(r'\\d', '0', text)\n","  return normalized_text\n","\n","def preprocess_dataset(sequences):\n","  sequences = [[normalize_number(w) for w in words] for words in sequences]\n","  return sequences\n","\n","def create_dataset(sequences, vocab):\n","  sequences = vocab.encode(sequences)\n","  sequences = pad_sequences(sequences, padding = 'post')\n","  return sequences\n","\n","\n","#models.py\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import Dense, Input, Embedding, LSTM\n","from tensorflow.keras.layers import Bidirectional\n","\n","class BidirectionalModel:\n","\n","  def __init__(self, input_dim, output_dim, emb_dim = 100, hid_dim = 100):\n","    self.input = Input(shape = (None,), name = 'input')\n","    self.embedding = Embedding(input_dim = input_dim, output_dim = emb_dim, mask_zero = True, name = 'embedding')\n","    lstm = LSTM(hid_dim, return_sequences = True, name = 'lstm')\n","    self.bilstm = Bidirectional(lstm, name = 'bilstm')\n","    self.fc = Dense(output_dim, activation = 'softmax')\n","\n","  def build(self):\n","    x = self.input\n","    embedding = self.embedding(x)\n","    lstm = self.bilstm(embedding)\n","    y = self.fc(lstm)\n","    return Model(inputs = x, outputs = y)\n","\n","\n","#inference.py\n","import numpy as np\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","\n","class InferenceAPI:\n","\n","  def __init__(self, model, source_vocab, target_vocab):\n","    self.model = model\n","    self.source_vocab = source_vocab\n","    self.target_vocab = target_vocab\n","\n","  def predict_from_sequences(self, sequences):\n","    lengths = map(len, sequences)\n","    sequences = self.source_vocab.encode(sequences)\n","    sequences = pad_sequences(sequences, padding = 'post')\n","    y_pred = self.model.predict(sequences)\n","    y_pred = np.argmax(y_pred, axis = -1)\n","    y_pred = self.target_vocab.decode(y_pred)\n","    y_pred = [y[:l] for y ,l in zip(y_pred, lengths)]\n","    return y_pred\n","\n","\n","#系列ラベルの評価用パッケージであるseqevalのインストール\n","!pip install seqeval\n","\n","\n","#train.py\n","from sklearn.model_selection import train_test_split\n","from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n","from tensorflow.keras.models import load_model\n","from seqeval.metrics import classification_report\n","\n","#from inference import InferenceAPI\n","#from models import BidirectionalModel\n","#from preprocessing import create_dataset, preprocess_dataset, Vocab\n","#from utils import load_dataset\n","\n","def main():\n","  #ハイパーパラメータの設定\n","  batch_size = 32\n","  epochs = 100\n","  model_path = 'models/bidirectional_model.5h'\n","  num_words = 15000\n","\n","  #データセットの読み込み\n","  x, y = load_dataset('ja.wikipedia.conll')\n","\n","  #データセットの前処理\n","  x = preprocess_dataset(x)\n","  x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 42)\n","  source_vocab = Vocab(num_words  = num_words, oov_token = '<UNK>').fit(x_train)\n","  target_vocab = Vocab(lower = False).fit(y_train)\n","  x_train = create_dataset(x_train, source_vocab)\n","  y_train = create_dataset(y_train, target_vocab)\n","\n","  #モデルの構築\n","  model = BidirectionalModel(num_words, target_vocab.size).build()\n","  model.compile(optimizer = 'adam',\n","                loss = 'sparse_categorical_crossentropy')\n","  \n","  #コールバックの用意\n","  callbacks = [\n","      EarlyStopping(patience = 3),\n","      ModelCheckpoint(model_path, save_best_only = True)\n","  ]\n","\n","  #モデルの学習\n","  model.fit(x = x_train, y = y_train, batch_size = batch_size, epochs = epochs, validation_split = 0.2, callbacks = callbacks, shuffle = True)\n","  \n","  #予測\n","  model = load_model(model_path)\n","  api = InferenceAPI(model, source_vocab, target_vocab)\n","  y_pred = api.predict_from_sequences(x_test)\n","  print(classification_report(y_test, y_pred, digits = 4))\n","\n","main()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tIAibm4Jd-zh","outputId":"6fea422f-c5c8-44d9-d29b-7e049c18a3af"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting seqeval\n","  Downloading seqeval-1.2.2.tar.gz (43 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 KB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.9/dist-packages (from seqeval) (1.22.4)\n","Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.9/dist-packages (from seqeval) (1.2.2)\n","Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.9/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.10.1)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn>=0.21.3->seqeval) (3.1.0)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.1.1)\n","Building wheels for collected packages: seqeval\n","  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16179 sha256=7c96b1b4579ea2f9882d7c8f4af4080a3583874cccc97f8bb50a0469328fb81b\n","  Stored in directory: /root/.cache/pip/wheels/e2/a5/92/2c80d1928733611c2747a9820e1324a6835524d9411510c142\n","Successfully built seqeval\n","Installing collected packages: seqeval\n","Successfully installed seqeval-1.2.2\n","Epoch 1/100\n","20/20 [==============================] - ETA: 0s - loss: 2.0089"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r20/20 [==============================] - 88s 3s/step - loss: 2.0089 - val_loss: 1.0328\n","Epoch 2/100\n","20/20 [==============================] - ETA: 0s - loss: 0.8747"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r20/20 [==============================] - 74s 4s/step - loss: 0.8747 - val_loss: 0.8382\n","Epoch 3/100\n","20/20 [==============================] - ETA: 0s - loss: 0.8085"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r20/20 [==============================] - 47s 2s/step - loss: 0.8085 - val_loss: 0.8108\n","Epoch 4/100\n","20/20 [==============================] - ETA: 0s - loss: 0.7653"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r20/20 [==============================] - 51s 3s/step - loss: 0.7653 - val_loss: 0.7571\n","Epoch 5/100\n","20/20 [==============================] - ETA: 0s - loss: 0.6909"]}]},{"cell_type":"code","source":["#10-8 BERT\n","#ColabではRAMクラッシュする！\n","\n","#事前言語処理向けモデルを多数含むパッケージであるtransformarsのインストール（その中にBERTもある)\n","!pip install transformers\n","\n","\n","#preprocessing.py\n","import re\n","\n","import tensorflow as tf\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","\n","class Vocab:\n","\n","  def __init__(self, num_words = None, lower = True, oov_token = None):\n","    self.tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words = num_words, oov_token = oov_token, filters = '', lower = lower, split = '\\t')\n","\n","  def fit(self, sequences):\n","    texts = self._texts(sequences)\n","    self.tokenizer.fit_on_texts(texts)\n","    return self\n","\n","  def encode(self, sequences):\n","    texts = self._texts(sequences)\n","    return self.tokenizer.texts_to_sequences(texts)\n","\n","  def decode(self, sequences):\n","    texts = self.tokenizer.sequences_to_texts(sequences)\n","    return [text.split(' ') for text in texts]\n","\n","  def _texts(self, sequences):\n","    return ['\\t'.join(words) for words in sequences]\n","\n","  def get_index(self, word):\n","    return self.tokenizer.word_index.get(word)\n","\n","  @property\n","  def size(self):\n","    return len(self.tokenizer.word_index) + 1\n","\n","  def save(self, file_path):\n","    with open(file_path, 'w') as f:\n","      config = self.tokenizer.to_json()\n","      f.write(config)\n","\n","  @classmethod\n","  def load(cls, file_path):\n","    with open(file_path) as f:\n","      tokenizer = tf.keras.preprocessing.text.tokenizer_from_json(f_read())\n","      vocab = cls()\n","      vocab.tokenizer = tokenizer\n","    return vocab\n","\n","\n","def normalize_number(text, reduce = True):\n","  if reduce:\n","    normalized_text = re.sub(r'\\d+', '0', text)\n","  else:\n","    normalized_text = re.sub(r'\\d', '0', text)\n","  return normalized_text\n","\n","def preprocess_dataset(sequences):\n","  sequences = [[normalize_number(w) for w in words] for words in sequences]\n","  return sequences\n","\n","def create_dataset(sequences, vocab):\n","  sequences = vocab.encode(sequences)\n","  sequences = pad_sequences(sequences, padding = 'post')\n","  return sequences\n","\n","def convert_examples_to_features(x, y, vocab, max_seq_length, tokenizer):\n","  pad_token = 0\n","  features = {\n","      'input_ids': [],\n","      'attention_mask': [],\n","      'token_type_ids': [],\n","      'label_ids': []\n","  }\n","  for words, labels in zip(x, y):\n","    tokens = [tokenizer.cls_token]\n","    label_ids = [pad_token]\n","    for word, label in zip(words, labels):\n","      word_tokens = tokenizer.tokenize(word)\n","      tokens.extend(word_tokens)\n","      label_id = vocab.get_index(label)\n","      label_ids.extend([label_id] + [pad_token] * (len(word_tokens) - 1))\n","    tokens += [tokenizer.sep_token]\n","\n","    input_ids = tokenizer.convert_tokens_to_ids(tokens)\n","    attention_mask = [1] * len(input_ids)\n","    token_type_ids = [pad_token] * max_seq_length\n","\n","    features['input_ids'].append(input_ids)\n","    features['attention_mask'].append(attention_mask)\n","    features['token_type_ids'].append(token_type_ids)\n","    features['label_ids'].append(label_ids)\n","\n","  for name in features:\n","    features[name] = pad_sequences(features[name], padding = 'post', maxlen = max_seq_length)\n","\n","  x = [features['input_ids'], features['attention_mask'], features['token_type_ids']]\n","  y = features['label_ids']\n","  return x, y\n","\n","\n","#models.py\n","\n","import tensorflow as tf\n","from transformers import TFBertForTokenClassification, BertConfig\n","\n","def build_model(pretrained_model_name_or_path, num_labels):\n","  config = BertConfig.from_pretrained(\n","      pretrained_model_name_or_path,\n","      num_labels = num_labels\n","  )\n","  model = TFBertForTokenClassification.from_pretrained(\n","      pretrained_model_name_or_path,\n","      config = config\n","  )\n","  model.layers[-1].activation = tf.keras.activations.softmax\n","  return model\n","\n","def loss_func(num_labels):\n","  loss_fct = tf.keras.losses.SparseCategoricalCrossentropy(reduction = tf.keras.losses.Reduction.NONE)\n","\n","  def loss(y_true, y_pred):\n","    pad_token = 0\n","    input_mask = tf.not_equal(y_true, pad_token) #pad_tokenと一致する部分をFalseにして無視する\n","    logits = tf.reshape(y_pred, (-1, num_labels)) #y_predを(帳尻の合う行, num_words)型に変換\n","    active_loss = tf.reshape(input_mask, (-1,))\n","    active_logits = tf.boolean_mask(logits, active_loss)\n","    train_labels = tf.reshape(y_true, (-1,))\n","    active_labels = tf.boolean_mask(train_labels, active_loss)\n","    cross_entropy = loss_fct(active_labels, active_logits)\n","    return cross_entropy\n","  return loss\n","\n","\n","#utils.py\n","def load_dataset(filename, encoding = 'utf-8'):\n","  sents, labels = [], []\n","  words, tags = [], []\n","  with open(filename, encoding = encoding) as f:\n","    for line in f:\n","      line = line.rstrip()\n","      if line:\n","        word, tag = line.split('\\t')\n","        words.append(word)\n","        tags.append(tag)\n","      else:\n","        sents.append(words)\n","        labels.append(tags)\n","        words, tags = [], []\n","    if words:\n","      sents.append(words)\n","      labels.append(tags)\n","\n","  return sents, labels\n","\n","def evaluate(model, target_vocab, features, labels):\n","  label_ids = model.predict(features)\n","  label_ids = np.argmax(label_ids, axis = -1)\n","  y_pred = [[] for _ in range(label_ids.shape[0])]\n","  y_true = [[] for _ in range(label_ids.shape[0])]\n","  for i in range(label_ids.shape[0]):\n","    for j in range(label_ids.shape[1]):\n","      if labels[i][j] == 0:\n","        continue\n","      y_pred[i].append(label_ids[i][j])\n","      y_true[i].append(labels[i][j])\n","  y_pred = target_vocab.decose(y_pred)\n","  y_ture = target_vocab.decode(y_ture)\n","  print(classification_report(y_true, y_pred, digits = 4))\n","\n","\n","#train_bert.py\n","from sklearn.model_selection import train_test_split\n","from tensorflow.keras.callbacks import EarlyStopping\n","from transformers import BertJapaneseTokenizer\n","\n","#from models import build_model, loss_func\n","#from preprocessing import convert_examples_to_features, Vocab, Preprocess_dataset\n","#from utils import load_dataset, evaluate\n","\n","def main():\n","  #ハイパーパラメータの設定\n","  batch_size = 32\n","  epochs = 100\n","  model_path = 'models/'\n","  pretrained_model_name_or_path = 'cl-tohoku/bert-base-japanese-whole-word-masking'\n","  maxlen = 250\n","\n","  #データセットの読み込み\n","  x, y = load_dataset('ja.wikipedia.conll')\n","  tokenizer = BertJapaneseTokenizer.from_pretrained(pretrained_model_name_or_path, do_word_tokenize = False)\n","\n","  #データセットの前処理\n","  x = preprocess_dataset(x)\n","  x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 42)\n","  target_vocab = Vocab(lower = False).fit(y_train)\n","  features_train, labels_train = convert_examples_to_features(\n","      x_train,\n","      y_train,\n","      target_vocab,\n","      max_seq_length = maxlen,\n","      tokenizer = tokenizer\n","  )\n","  features_test, labels_test = convert_examples_to_features(\n","      x_test,\n","      y_test,\n","      target_vocab,\n","      max_seq_length = maxlen,\n","      tokenizer = tokenizer\n","  )\n","\n","  #モデルの構築\n","  model = build_model(pretrained_model_name_or_path, target_vocab.size)\n","  model.compile(optimizer = 'sgd', loss = loss_func(target_vocab.size))\n","  \n","  #コールバックの用意\n","  callbacks = [\n","      EarlyStopping(patience = 3),\n","  ]\n","\n","  #モデルの学習\n","  model.fit(\n","      x = features_train, \n","      y = labels_train, \n","      batch_size = batch_size, \n","      epochs = epochs, \n","      validation_split = 0.1, \n","      callbacks = callbacks, \n","      shuffle = True)\n","  model.save_pretrained(model_path)\n","\n","  #性能の評価\n","  evaluate(model, target_vocab, features_test, labels_test)\n","\n","main()"],"metadata":{"id":"9c0mY26KjmyR","colab":{"base_uri":"https://localhost:8080/"},"outputId":"0151dce4-4458-4829-9627-40f9320d6e17"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: transformers in /usr/local/lib/python3.9/dist-packages (4.26.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers) (3.9.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (0.13.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from transformers) (2.25.1)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (0.13.2)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (2022.6.2)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (1.22.4)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/dist-packages (from transformers) (4.65.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (23.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2022.12.7)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (1.26.14)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (4.0.0)\n"]},{"output_type":"stream","name":"stderr","text":["All model checkpoint layers were used when initializing TFBertForTokenClassification.\n","\n","Some layers of TFBertForTokenClassification were not initialized from the model checkpoint at cl-tohoku/bert-base-japanese-whole-word-masking and are newly initialized: ['classifier']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n"]}]},{"cell_type":"code","source":["#11-4 系列変換\n","\n","#BLEUを指標とした評価をするためにNLTKをインポート\n","!pip install nltk\n","\n","#utils.py\n","def load_dataset(filename):\n","  en_texts = []\n","  ja_texts = []\n","  with open(filename, encoding = 'utf-8') as f:\n","    for line in f\n","      en_text, ja_text = line.strip().split('\\t')[:2]\n","      en_texts.append(en_text)\n","      ja_texts.append(ja_text)\n","  return en_texts, ja_texts\n","\n","from collections import defaultdict\n","from nltk.translate.bleu_score import corpus_bleu\n","def evaluate_bleu(X, y, api):\n","  \n","\n","#preprocessing.py\n","import tensorflow as tf\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from janome.tokenizer import Tokenizer\n","t = Tokenizer(wakati = True)\n","\n","def build_vocabulary(texts, num_words = None):\n","  tokenizer = tf.keras.preprocessing.text.Tokenizer(\n","      num_words = num_words, oov_token = '<UNK>', filters = ''\n","  )\n","  tokenizer.fit_on_texts(texts)\n","  return tokenizer\n","\n","def tokenize(text):\n","  return t.tokenize(text)\n","\n","def preprocess_dataset(texts):\n","  return ['<start> {} <end>'.format(text) for text in texts]\n","\n","def create_dataset(en_texts, ja_texts, en_vocab, ja_vocab):\n","  en_seqs = en_vocab.texts_to_sequences(en_texts)\n","  ja_seqs = ja_vocab.texts_to_sequences(ja_texts)\n","  en_seqs = pad_sequences(en_seqs, padding = 'post')\n","  ja_seqs = pad_sequences(ja_seqs, padding = 'post')\n","  return [en_seqs, ja_seqs[:, :-1]], ja_seqs[:, 1:]\n","\n","\n","#models.py\n","from tensorflow.keras.models import Model, model_from_json\n","from tensorflow.keras.layers import Dense, Input, Embedding, GRU\n","\n","class BaseModel:\n","\n","  def build(self):\n","    raise NotImplementedError()\n","\n","  def save_as_json(self, filepath):\n","    model = self.build()\n","    with open(filepath, 'w') as f:\n","      f.write(model.to_json())\n","\n","  @classmethod\n","  def load(cls, architecture_file, weight_file, by_name = True):\n","    with open(architecture_file) as f:\n","      model = model_from_json(f_read())\n","      model.load_weights(weight_file, by_name = by_name)\n","      return model\n","\n","class Encoder(BaseModel):\n","\n","  def __init__(self, input_dim, emb_dim = 300, hid_dim = 256, return_sequences = False):\n","    self.input = Input(shape = (None,), name = 'encoder_input')\n","    self.embedding = Embedding(\n","        input_dim = input_dim,\n","        output_dim = emb_dim,\n","        mask_zero = True,\n","        name = 'encoder_embedding'\n","        )\n","    self.gru = GRU(\n","        hid_dim,\n","        return_sequences = return_sequences,\n","        return_state = True,\n","        name = 'encoder_gru'\n","        )\n","    \n","  def __call__(self):\n","    x = self.input\n","    embedding = self.embedding(x)\n","    output, state = self.gru(embedding)\n","    return output, state\n","\n","  def build(self):\n","    output, state = self()\n","    return Model(inputs = self.input, outputs = [output, state])\n","\n","class Seq2seq(BaseModel):\n","\n","  def __init__(self, encoder, decoder):\n","    self.encoder = encoder\n","    self.decoder = decoder\n","\n","  def build(self):\n","    encoder_output, state = self.encoder()\n","    decoder_output, _ = self.decoder(states = state, enc_output = encoder_output)\n","    return Model([self.encoder.input, self.decoder_input], decoder_output)\n","\n","#inference.py\n","import numpy as np\n","\n","class InferenceAPI:\n","\n","  def __init__(self, encoder_model, decoder_model, en_vocab, ja_vocab):\n","    self.encoder_model = encoder_model\n","    self.decoder_model = decoder_model\n","    self.en_vocab = en_vocab\n","    self.ja_vocab = ja_vocab\n","\n","  def predict(self, text):\n","    output, state = sself._compute_encoder_output(text)\n","    sequence = self._generate_sequences(output, state)\n","    docoded = self._decode(sequence)\n","    return decoded\n","\n","  def _compute_encoder_output(self, text):\n","    x = self.en_vocab.texts_to_sequences([text])\n","    output, state = self.encoder_model.predict(x)\n","    return output, state\n","\n","  def _compute_decoder_output(self, target_seq, state, enc_output = None):\n","    ooutput, state = self.decoder_model.predict([target_seq, state])\n","\n","  def _generate_sequence(self, enc_output, state, max_seq_len = 50):\n","    target_seq = np.array([self.ja_vocab.word_index['<start>']])\n","    sequence = []\n","    for i in range(max_seq_len):\n","      output, state = self._compute_decoder_output(target_seq, state, enc_output)\n","      sampled_token_index = np.argmax(output[0, 0])\n","      if sampled_token_index == self.ja_vocab.word_index['<end>']:\n","        break\n","      sequence.append(sampled_token_index)\n","      target_seq = np.array([sampled_token_index])\n","    return sequence\n","\n","  def _decode(self, sequence):\n","    secoded = self.ja_vocab.sequences_to_texts([sequence])\n","    decoded = decoded[0].aplit(' ')\n","    return decoded\n","\n","\n","#train.py"],"metadata":{"id":"xuv6jfjUNx11"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"j1ISFDHDJ_zG"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPgXP6YQhW9FA8ZvkWejyYc"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}